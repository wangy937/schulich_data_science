{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 已输出：/Users/sam/Desktop/cninfo_output/募集说明书链接_选取公司【募集】.xlsx（工作表：募集说明书）\n",
      "---- 募集说明书检索完成 ----\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "02_collect_offering_links.py\n",
    "功能：按《正股映射结果.xlsx》的公司集合，从巨潮接口检索“募集说明书”公告，\n",
    "     并导出 Excel（格式与年报版一致，只是标题/年份/链接改为募集说明书对应内容）。\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import requests\n",
    "import openpyxl\n",
    "import pandas as pd\n",
    "from typing import List, Dict, Tuple\n",
    "from datetime import date\n",
    "\n",
    "# ========= 可调参数 =========\n",
    "# 关键词：改为“募集说明书”\n",
    "KEYWORDS = [\"募集说明书\"]\n",
    "EXTRA_KWS: List[str] = []   # 可追加“更新稿”、“摘要”等\n",
    "\n",
    "# 时间范围（起止）\n",
    "DATE_BEGIN = \"2000-02-01\"\n",
    "DATE_END   = date.today().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "output_dir   = os.path.expanduser(\"~/Desktop/cninfo_output\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "mapping_file = os.path.expanduser(\"~/Desktop/正股映射结果.xlsx\")\n",
    "\n",
    "# 输出文件\n",
    "OUT_XLSX = os.path.join(output_dir, \"募集说明书链接_选取公司【募集】.xlsx\")\n",
    "SHEET    = \"募集说明书\"\n",
    "\n",
    "# 市场/板块\n",
    "MARKETS = [\"szse\", \"shse\"]\n",
    "PLATES  = [\"\", \"sz\", \"szmb\", \"szcy\", \"sh\", \"shmb\", \"shkcp\", \"bj\"]\n",
    "\n",
    "# 排除干扰词\n",
    "EXCLUDE_KWS = [\n",
    "    \"英文\", \"英文版\", \"Annual\", \"annual\", \"Summary\", \"summary\",\n",
    "    \"摘要\", \"摘要版\", \"取消\", \"已取消\", \"提示性公告\", \"更名提示\", \"B股\", \"H股\"\n",
    "]\n",
    "\n",
    "# ========= 工具函数 =========\n",
    "_SPACE_RE = re.compile(r\"[\\s\\u00A0\\u3000]+\")\n",
    "def norm(s: str) -> str:\n",
    "    return _SPACE_RE.sub(\"\", str(s or \"\").strip())\n",
    "\n",
    "def any_kw_in(text: str, kws: List[str]) -> bool:\n",
    "    t = norm(text)\n",
    "    return any(norm(k) in t for k in kws if k)\n",
    "\n",
    "_TITLE_YEAR_PATS = [\n",
    "    re.compile(r\"(20\\d{2})\\s*年?\\s*度?\\s*募\\s*集\\s*说\\s*明\\s*书\"),\n",
    "    re.compile(r\"(20\\d{2})\\s*年?\\s*募\\s*集\\s*说\\s*明\\s*书\"),\n",
    "    re.compile(r\"(19\\d{2}|20\\d{2})\")\n",
    "]\n",
    "def extract_year_from_title(title: str) -> str:\n",
    "    t = norm(title)\n",
    "    for pat in _TITLE_YEAR_PATS:\n",
    "        m = pat.search(t)\n",
    "        if m:\n",
    "            return m.group(1)\n",
    "    return \"\"\n",
    "\n",
    "def year_from_timestamp_ms(ts: int) -> str:\n",
    "    try:\n",
    "        return time.strftime(\"%Y\", time.localtime(int(ts)/1000))\n",
    "    except Exception:\n",
    "        return \"\"\n",
    "\n",
    "def is_target_offering(title: str) -> bool:\n",
    "    kws = list(KEYWORDS) + list(EXTRA_KWS)\n",
    "    t = norm(title)\n",
    "    if not any_kw_in(t, kws):\n",
    "        return False\n",
    "    if any_kw_in(t, EXCLUDE_KWS):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def ann_weight(it: Dict) -> Tuple[int, int]:\n",
    "    title = norm(it.get(\"announcementTitle\", \"\"))\n",
    "    w_fix = 0\n",
    "    if any_kw_in(title, [\"更新\", \"修订\", \"更正\"]):\n",
    "        w_fix = 10\n",
    "    try:\n",
    "        ts = int(it.get(\"announcementTime\", 0))\n",
    "    except Exception:\n",
    "        ts = 0\n",
    "    return (w_fix, ts)\n",
    "\n",
    "# ========= 调接口 =========\n",
    "def get_report(page_num: int, date_range: str, column: str, plate: str, searchkey: str=\"\") -> requests.Response:\n",
    "    url = \"http://www.cninfo.com.cn/new/hisAnnouncement/query\"\n",
    "    payload = {\n",
    "        \"pageNum\":   page_num,\n",
    "        \"pageSize\":  30,\n",
    "        \"column\":    column,\n",
    "        \"tabName\":   \"fulltext\",\n",
    "        \"category\":  \"\",\n",
    "        \"plate\":     plate,\n",
    "        \"searchkey\": searchkey,\n",
    "        \"secid\":     \"\",\n",
    "        \"trade\":     \"\",\n",
    "        \"seDate\":    date_range,\n",
    "        \"sortName\":  \"code\",\n",
    "        \"sortType\":  \"asc\",\n",
    "        \"isHLtitle\": \"false\"\n",
    "    }\n",
    "    headers = {\n",
    "        \"Accept\":           \"*/*\",\n",
    "        \"Accept-Language\":  \"zh-CN,zh;q=0.9\",\n",
    "        \"Content-Type\":     \"application/x-www-form-urlencoded; charset=UTF-8\",\n",
    "        \"Origin\":           \"http://www.cninfo.com.cn\",\n",
    "        \"Referer\":          \"http://www.cninfo.com.cn/new/commonUrl/pageOfSearch?url=disclosure/list/search\",\n",
    "        \"User-Agent\":       \"Mozilla/5.0\",\n",
    "        \"X-Requested-With\": \"XMLHttpRequest\"\n",
    "    }\n",
    "    return requests.post(url, data=payload, headers=headers, timeout=15)\n",
    "\n",
    "def download_for_segments(segments: List[str], column: str, plate: str, searchkey: str) -> List[Dict]:\n",
    "    all_ann: List[Dict] = []\n",
    "    seen = set()\n",
    "    for date_range in segments:\n",
    "        try:\n",
    "            total = get_report(1, date_range, column, plate, searchkey).json().get(\"totalpages\", 0)\n",
    "        except Exception:\n",
    "            continue\n",
    "        if total <= 0:\n",
    "            continue\n",
    "\n",
    "        page = 1\n",
    "        while page <= total:\n",
    "            for _ in range(3):\n",
    "                try:\n",
    "                    resp = get_report(page, date_range, column, plate, searchkey)\n",
    "                    resp.raise_for_status()\n",
    "                    anns = resp.json().get(\"announcements\", []) or []\n",
    "                    for x in anns:\n",
    "                        title = x.get(\"announcementTitle\", \"\")\n",
    "                        if not is_target_offering(title):\n",
    "                            continue\n",
    "                        key = (str(x.get(\"secCode\", \"\")), str(x.get(\"adjunctUrl\", \"\")))\n",
    "                        if key in seen:\n",
    "                            continue\n",
    "                        seen.add(key)\n",
    "                        all_ann.append(x)\n",
    "                    break\n",
    "                except Exception:\n",
    "                    time.sleep(1.2)\n",
    "            page += 1\n",
    "    return all_ann\n",
    "\n",
    "def collect_all_offering() -> List[Dict]:\n",
    "    y_begin = int(DATE_BEGIN[:4])\n",
    "    y_end   = int(DATE_END[:4])\n",
    "    segments: List[str] = []\n",
    "    for y in range(y_begin, y_end + 1):\n",
    "        seg_start = f\"{y}-01-01\" if y > y_begin else DATE_BEGIN\n",
    "        seg_end   = f\"{y}-12-31\" if y < y_end   else DATE_END\n",
    "        segments.append(f\"{seg_start}~{seg_end}\")\n",
    "\n",
    "    search_terms = list({norm(k) for k in (KEYWORDS + EXTRA_KWS) if k})\n",
    "    raw: List[Dict] = []\n",
    "    for col in MARKETS:\n",
    "        for pl in PLATES:\n",
    "            for kw in (search_terms or [\"募集说明书\"]):\n",
    "                raw.extend(download_for_segments(segments, col, pl, kw))\n",
    "    return raw\n",
    "\n",
    "# ========= 去重 =========\n",
    "def filter_latest_per_company(anns: List[Dict], valid_secs: set) -> List[Dict]:\n",
    "    latest: Dict[Tuple[str, str], Dict] = {}\n",
    "    for it in anns:\n",
    "        sec = str(it.get(\"secCode\", \"\"))\n",
    "        if sec not in valid_secs:\n",
    "            continue\n",
    "        yr = extract_year_from_title(it.get(\"announcementTitle\", \"\")) or year_from_timestamp_ms(it.get(\"announcementTime\", 0))\n",
    "        if not yr:\n",
    "            continue\n",
    "        key = (sec, yr)\n",
    "        if key not in latest or ann_weight(it) > ann_weight(latest[key]):\n",
    "            latest[key] = it\n",
    "    return list(latest.values())\n",
    "\n",
    "# ========= 写 Excel =========\n",
    "def write_selected_excel(anns: List[Dict]) -> None:\n",
    "    df_map = pd.read_excel(mapping_file, dtype=str).fillna(\"\")\n",
    "    df_map[\"sec_no_suf\"] = df_map[\"正股代码\"].str.split(\".\").str[0]\n",
    "\n",
    "    ann_dict: Dict[Tuple[str, str], Dict] = {}\n",
    "    for it in anns:\n",
    "        sec = str(it.get(\"secCode\", \"\"))\n",
    "        yr  = extract_year_from_title(it.get(\"announcementTitle\", \"\")) or year_from_timestamp_ms(it.get(\"announcementTime\", 0))\n",
    "        if sec and yr:\n",
    "            ann_dict[(sec, yr)] = it\n",
    "\n",
    "    wb = openpyxl.Workbook()\n",
    "    ws = wb.active\n",
    "    ws.title = SHEET\n",
    "    ws.append([\"可转债代码\",\"可转债名称\",\"公司代码\",\"公司简称\",\"标题\",\"年份\",\"年报链接\"])\n",
    "\n",
    "    for _, row in df_map.iterrows():\n",
    "        bond_code = row.get(\"代码\", \"\")\n",
    "        bond_name = row.get(\"名称\", \"\")\n",
    "        sec       = row.get(\"sec_no_suf\", \"\")\n",
    "        comp_name = row.get(\"正股名称\", \"\")\n",
    "\n",
    "        matched = [(k, v) for k, v in ann_dict.items() if k[0] == sec]\n",
    "        if matched:\n",
    "            matched.sort(key=lambda kv: kv[0][1])\n",
    "            for (_, yr), it in matched:\n",
    "                raw_title = re.sub(r\"<.*?>\",\"\", it.get(\"announcementTitle\",\"\")).replace(\"：\",\"\")\n",
    "                title = f\"《{raw_title}》\"\n",
    "                url   = f\"http://static.cninfo.com.cn/{it.get('adjunctUrl','')}\"\n",
    "                ws.append([bond_code, bond_name, sec, comp_name, title, yr, url])\n",
    "        else:\n",
    "            ws.append([bond_code, bond_name, sec, comp_name, \"\", \"\", \"\"])\n",
    "\n",
    "    wb.save(OUT_XLSX)\n",
    "    print(f\"✅ 已输出：{OUT_XLSX}（工作表：{SHEET}）\")\n",
    "\n",
    "# ========= 主流程 =========\n",
    "def main():\n",
    "    df_map = pd.read_excel(mapping_file, dtype=str).fillna(\"\")\n",
    "    valid_secs = set(df_map[\"正股代码\"].str.split(\".\").str[0].tolist())\n",
    "\n",
    "    raw = collect_all_offering()\n",
    "    picked = filter_latest_per_company(raw, valid_secs)\n",
    "    write_selected_excel(picked)\n",
    "    print(\"---- 募集说明书检索完成 ----\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
