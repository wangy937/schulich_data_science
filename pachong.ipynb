{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###æ— åˆ å‡æ›´æ­£ç‰ˆè¿™ç§ç±»å‹çš„code\n",
    "#!/usr/bin/env python\n",
    "# -*- coding: UTF-8 -*-\n",
    "'''\n",
    "@Project ï¼šPycharmProjects\n",
    "@File    ï¼šå·¨æ½®èµ„è®¯å¹´æŠ¥2.0.py\n",
    "@IDE     ï¼šPyCharm\n",
    "@Author  ï¼šlingxiaotian\n",
    "@Date    ï¼š2023/5/20 12:38\n",
    "'''\n",
    "\n",
    "import requests\n",
    "import re\n",
    "import openpyxl\n",
    "import time\n",
    "import os\n",
    "\n",
    "\n",
    "# æ”¾åˆ°æ¡Œé¢ä¸Šçš„ cninfo_output æ–‡ä»¶å¤¹\n",
    "output_dir = os.path.expanduser(\"~/Desktop/cninfo_output\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "\n",
    "GZH = \"ã€å¹´æŠ¥ã€‘\"\n",
    "def get_report(page_num, date):\n",
    "    url = \"http://www.cninfo.com.cn/new/hisAnnouncement/query\"\n",
    "    headers = {\n",
    "        \"Accept\": \"*/*\",\n",
    "        \"Accept-Encoding\": \"gzip, deflate\",\n",
    "        \"Accept-Language\": \"zh-CN,zh;q=0.9,en;q=0.8,en-GB;q=0.7,en-US;q=0.6\",\n",
    "        \"Content-Length\": \"195\",\n",
    "        \"Content-Type\": \"application/x-www-form-urlencoded; charset=UTF-8\",\n",
    "        \"Host\": \"www.cninfo.com.cn\",\n",
    "        \"Origin\": \"http://www.cninfo.com.cn\",\n",
    "        \"Proxy-Connection\": \"keep-alive\",\n",
    "        \"Referer\": \"http://www.cninfo.com.cn/new/commonUrl/pageOfSearch?url=disclosure/list/search&checkedCategory=category_ndbg_szsh\",\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/113.0.0.0 Safari/537.36 Edg/113.0.1774.42\",\n",
    "        \"X-Requested-With\": \"XMLHttpRequest\"\n",
    "    }\n",
    "    data = {\n",
    "        \"pageNum\": page_num,\n",
    "        \"pageSize\": 30,\n",
    "        \"column\": \"szse\",\n",
    "        \"tabName\": \"fulltext\",\n",
    "        \"plate\": plate,\n",
    "        \"searchkey\": \"\",\n",
    "        \"secid\": \"\",\n",
    "        \"category\": \"category_ndbg_szsh\",\n",
    "        \"trade\": trade,\n",
    "        \"seDate\": date,\n",
    "        \"sortName\": \"code\",\n",
    "        \"sortType\": \"asc\",\n",
    "        \"isHLtitle\": \"false\"\n",
    "    }\n",
    "    response = requests.post(url, data=data, headers=headers)\n",
    "    return response\n",
    "\n",
    "# å‘é€HTTPè¯·æ±‚å¹¶è·å–å“åº”\n",
    "def download_report(date):\n",
    "    global counter\n",
    "    all_results = []\n",
    "    page_num = 1\n",
    "    response_test = get_report(page_num, date)\n",
    "\n",
    "    try:\n",
    "        data_test = response_test.json()\n",
    "        total_pages = data_test.get(\"totalpages\", 0)\n",
    "        if total_pages == 0:\n",
    "            return all_results\n",
    "    except (ValueError, KeyError) as e:\n",
    "        print(f\"è·å–æ€»é¡µæ•°å¤±è´¥: {e}\")\n",
    "        return all_results\n",
    "\n",
    "    max_retries = 3\n",
    "    while page_num <= total_pages + 1:\n",
    "        retry_count = 0\n",
    "        while retry_count <= max_retries:\n",
    "            try:\n",
    "                response = get_report(page_num, date)\n",
    "                response.raise_for_status()\n",
    "                data = response.json()\n",
    "                if not data.get(\"announcements\"):\n",
    "                    break\n",
    "                all_results.extend(data[\"announcements\"])\n",
    "                if total_pages > 0:\n",
    "                    per = (counter / total_pages)\n",
    "                    if per < 1:\n",
    "                        print(f\"\\rå½“å‰å¹´ä»½ä¸‹è½½è¿›åº¦ {per * 100:.2f} %\", end='')\n",
    "                    else:\n",
    "                        print(f\"\\rä¸‹è½½å®Œæˆï¼Œæ­£åœ¨ä¿å­˜â€¦â€¦\", end='')\n",
    "                else:\n",
    "                    print(\"æ— æ³•è®¡ç®—ä¸‹è½½è¿›åº¦ï¼Œæ€»é¡µæ•°ä¸º0ã€‚\")\n",
    "                break\n",
    "            except requests.exceptions.RequestException as e:\n",
    "                print(f\"å‡ºç°ç½‘ç»œè¯·æ±‚é”™è¯¯ï¼: {e}\")\n",
    "                print(\"5ç§’åé‡è¯•...\")\n",
    "                time.sleep(5)\n",
    "                retry_count += 1\n",
    "            except (ValueError, KeyError) as e:\n",
    "                print(f\"è§£æå“åº”æ•°æ®å¤±è´¥: {e}\")\n",
    "                print(\"5ç§’åé‡è¯•...\")\n",
    "                time.sleep(5)\n",
    "                retry_count += 1\n",
    "            if retry_count > max_retries:\n",
    "                print(f\"{max_retries}æ¬¡é‡è¯•åå‡å¤±è´¥. è·³è¿‡ç¬¬{page_num}é¡µ.\")\n",
    "                break\n",
    "        page_num += 1\n",
    "        counter += 1\n",
    "    return all_results\n",
    "\n",
    "def main(year):\n",
    "    global sum\n",
    "    date_count = f\"{year}-01-01~{year}-12-31\"\n",
    "    response = get_report(1, date_count)\n",
    "    data = response.json()\n",
    "    sum = data.get(\"totalpages\", 0)\n",
    "\n",
    "    year = year + 1\n",
    "    all_results = []\n",
    "    time_segments = [\n",
    "        f\"{year}-01-01~{year}-04-01\",\n",
    "        f\"{year}-04-02~{year}-04-15\",\n",
    "        f\"{year}-04-16~{year}-04-22\",\n",
    "        f\"{year}-04-23~{year}-04-26\",\n",
    "        f\"{year}-04-27~{year}-04-28\",\n",
    "        f\"{year}-04-29~{year}-04-30\",\n",
    "        f\"{year}-05-01~{year}-07-31\",\n",
    "        f\"{year}-08-01~{year}-10-31\",\n",
    "        f\"{year}-11-01~{year}-11-30\",\n",
    "        f\"{year}-12-01~{year}-12-31\"\n",
    "    ]\n",
    "    for segment in time_segments:\n",
    "        results = download_report(segment)\n",
    "        all_results.extend(results)\n",
    "\n",
    "    workbook = openpyxl.Workbook()\n",
    "    worksheet = workbook.active\n",
    "    worksheet.title = \"å¹´æŠ¥\"\n",
    "    worksheet.append([\"å…¬å¸ä»£ç \", \"å…¬å¸ç®€ç§°\", \"æ ‡é¢˜\", \"å¹´ä»½\", \"å¹´æŠ¥é“¾æ¥\"])\n",
    "\n",
    "    for item in all_results:\n",
    "        company_code = item[\"secCode\"]\n",
    "        company_name = item[\"secName\"]\n",
    "        title = item[\"announcementTitle\"].strip()\n",
    "        title = re.sub(r\"<.*?>\", \"\", title)\n",
    "        title = title.replace(\"ï¼š\", \"\")\n",
    "        title = f\"ã€Š{title}ã€‹\"\n",
    "        adjunct_url = item[\"adjunctUrl\"]\n",
    "        m = re.search(r\"(\\d{4})å¹´\", title)\n",
    "        year_str = m.group(1) if m else setYear\n",
    "        announcement_url = f\"http://static.cninfo.com.cn/{adjunct_url}\"\n",
    "        exclude_flag = any(kw in title for kw in exclude_keywords)\n",
    "        if not exclude_flag:\n",
    "            worksheet.append([company_code, company_name, title, year_str, announcement_url])\n",
    "\n",
    "    save_path = os.path.join(output_dir, f\"å¹´æŠ¥é“¾æ¥_{setYear}{GZH}.xlsx\")\n",
    "    workbook.save(save_path)\n",
    "    print(f\"å·²ä¿å­˜åˆ° {save_path}\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # æ’é™¤åˆ—è¡¨å¯ä»¥åŠ å…¥'æ›´æ­£å','ä¿®è®¢ç‰ˆ'æ¥è§„é¿æ•°æ®é‡å¤æˆ–å…¬å¸å‘å¸ƒä¹‹å‰å¹´ä»½çš„å¹´æŠ¥ä¿®è®¢ç‰ˆç­‰é—®é¢˜ï¼Œ\n",
    "    exclude_keywords = ['è‹±æ–‡','å·²å–æ¶ˆ','æ‘˜è¦']\n",
    "    # æ§åˆ¶è¡Œä¸šï¼Œè‹¥ä¸ºç©ºåˆ™ä¸æ§åˆ¶ï¼Œä»…å¯ä»å‚è€ƒå†…å®¹ä¸­é€‰å–ï¼Œä¸­é—´ç”¨è‹±æ–‡åˆ†å·éš”å¼€\n",
    "    # å‚è€ƒå†…å®¹ï¼š\"å†œã€æ—ã€ç‰§ã€æ¸”ä¸š;ç”µåŠ›ã€çƒ­åŠ›ã€ç‡ƒæ°”åŠæ°´ç”Ÿäº§å’Œä¾›åº”ä¸š;å»ºç­‘ä¸š;é‡‡çŸ¿ä¸š;åˆ¶é€ ä¸š;æ‰¹å‘å’Œé›¶å”®ä¸š;äº¤é€šè¿è¾“ã€ä»“å‚¨å’Œé‚®æ”¿ä¸š;ä½å®¿å’Œé¤é¥®ä¸š;ä¿¡æ¯ä¼ è¾“ã€è½¯ä»¶å’Œä¿¡æ¯æŠ€æœ¯æœåŠ¡ä¸š;é‡‘èä¸š;æˆ¿åœ°äº§ä¸š;ç§Ÿèµå’Œå•†åŠ¡æœåŠ¡ä¸š;ç§‘å­¦ç ”ç©¶å’ŒæŠ€æœ¯æœåŠ¡ä¸š;æ°´åˆ©ã€ç¯å¢ƒå’Œå…¬å…±è®¾æ–½ç®¡ç†ä¸š;å±…æ°‘æœåŠ¡ã€ä¿®ç†å’Œå…¶ä»–æœåŠ¡ä¸š;æ•™è‚²;å«ç”Ÿå’Œç¤¾ä¼šå·¥ä½œ;æ–‡åŒ–ã€ä½“è‚²å’Œå¨±ä¹ä¸š;ç»¼åˆ\"\n",
    "    trade = \"\"\n",
    "    # æ¿å—æ§åˆ¶ï¼šæ·±å¸‚sz æ²ªå¸‚sh æ·±ä¸»æ¿szmb æ²ªä¸»æ¿shmb åˆ›ä¸šæ¿szcy ç§‘åˆ›æ¿shkcp åŒ—äº¤æ‰€bj è¯·æŒ‰ç…§æ ¼å¼å¡«å†™\n",
    "    plate = \"sz;sh\"\n",
    "    # ========= å¯é€‰è®¾ç½®ï¼šè‡ªå®šä¹‰å…¬å¸åˆ—è¡¨ï¼Œä»…ä¸‹è½½æŒ‡å®šå…¬å¸å¹´æŠ¥ =========\n",
    "    # ç¤ºä¾‹ï¼š['600519', '000001']ï¼Œç•™ç©ºåˆ™ä¸‹è½½å…¨éƒ¨\n",
    "    secCode = ['300500','000670']\n",
    "    # ç¤ºä¾‹ï¼š['ä¸­é›†é›†å›¢', 'ä¸­æ´²æ§è‚¡']ï¼Œç•™ç©ºåˆ™ä¸‹è½½å…¨éƒ¨\n",
    "    secName = []\n",
    "\n",
    "\n",
    "    global counter\n",
    "    global sum\n",
    "    counter = 1\n",
    "    setYear = 2024\n",
    "    Flag = 0\n",
    "\n",
    "    def filter_excel(year):\n",
    "        if not secCode and not secName:\n",
    "            return\n",
    "        try:\n",
    "            src_path = os.path.join(output_dir, f\"å¹´æŠ¥é“¾æ¥_{year}{GZH}.xlsx\")\n",
    "            wb = openpyxl.load_workbook(src_path)\n",
    "            ws = wb.active\n",
    "            rows = list(ws.iter_rows(values_only=True))\n",
    "            header = rows[0]\n",
    "            filtered = [header] + [r for r in rows[1:]\n",
    "                                   if str(r[0]) in secCode or str(r[1]) in secName]\n",
    "            wb_new = openpyxl.Workbook()\n",
    "            ws_new = wb_new.active\n",
    "            for r in filtered:\n",
    "                ws_new.append(r)\n",
    "            dst_path = os.path.join(output_dir, f\"å¹´æŠ¥é“¾æ¥_{year}_é€‰å–å…¬å¸.xlsx\")\n",
    "            wb_new.save(dst_path)\n",
    "            print(f\"---- è¿‡æ»¤å®Œæˆ: {dst_path} å·²ç”Ÿæˆ\")\n",
    "        except Exception as e:\n",
    "            print(f\"---- è¿‡æ»¤å¤±è´¥: {e}ï¼Œå·²è·³è¿‡\")\n",
    "\n",
    "    if Flag:\n",
    "        for y in range(2020, setYear + 1):\n",
    "            counter = 1\n",
    "            main(y)\n",
    "            filter_excel(y)\n",
    "            print(f\"---- {y}å¹´ä¸‹è½½å®Œæˆ\")\n",
    "    else:\n",
    "        main(setYear)\n",
    "        filter_excel(setYear)\n",
    "        print(f\"---- {setYear}å¹´ä¸‹è½½å®Œæˆ\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ä¸‹è½½å®Œæˆï¼Œæ­£åœ¨ä¿å­˜â€¦â€¦.57%å·²ä¿å­˜åˆ° /Users/sam/Desktop/cninfo_output/å¹´æŠ¥é“¾æ¥_2024ã€å¹´æŠ¥ã€‘.xlsx\n",
      "è¿‡æ»¤å®Œæˆ: /Users/sam/Desktop/cninfo_output/å¹´æŠ¥é“¾æ¥_2024_é€‰å–å…¬å¸.xlsx å·²ç”Ÿæˆ\n",
      "----2024å¹´ä¸‹è½½å®Œæˆ\n"
     ]
    }
   ],
   "source": [
    "### æœ‰åˆ å‡æ›´æ­£ç‰ˆè¿™ç§ç±»å‹çš„code\n",
    "\n",
    "import requests\n",
    "import re\n",
    "import openpyxl\n",
    "import time\n",
    "import os\n",
    "\n",
    "# æ”¾åˆ°æ¡Œé¢ä¸Šçš„ cninfo_output æ–‡ä»¶å¤¹\n",
    "output_dir = os.path.expanduser(\"~/Desktop/cninfo_output\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "GZH = \"ã€å¹´æŠ¥ã€‘\"\n",
    "\n",
    "def get_report(page_num, date):\n",
    "    url = \"http://www.cninfo.com.cn/new/hisAnnouncement/query\"\n",
    "    headers = {\n",
    "        \"Accept\": \"*/*\",\n",
    "        \"Accept-Encoding\": \"gzip, deflate\",\n",
    "        \"Accept-Language\": \"zh-CN,zh;q=0.9,en;q=0.8,en-GB;q=0.7,en-US;q=0.6\",\n",
    "        \"Content-Length\": \"195\",\n",
    "        \"Content-Type\": \"application/x-www-form-urlencoded; charset=UTF-8\",\n",
    "        \"Host\": \"www.cninfo.com.cn\",\n",
    "        \"Origin\": \"http://www.cninfo.com.cn\",\n",
    "        \"Proxy-Connection\": \"keep-alive\",\n",
    "        \"Referer\": \"http://www.cninfo.com.cn/new/commonUrl/pageOfSearch?url=disclosure/list/search&checkedCategory=category_ndbg_szsh\",\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/113.0.0.0 Safari/537.36 Edg/113.0.1774.42\",\n",
    "        \"X-Requested-With\": \"XMLHttpRequest\"\n",
    "    }\n",
    "    data = {\n",
    "        \"pageNum\": page_num,\n",
    "        \"pageSize\": 30,\n",
    "        \"column\": \"szse\",\n",
    "        \"tabName\": \"fulltext\",\n",
    "        \"plate\": plate,\n",
    "        \"searchkey\": \"\",\n",
    "        \"secid\": \"\",\n",
    "        \"category\": \"category_ndbg_szsh\",\n",
    "        \"trade\": trade,\n",
    "        \"seDate\": date,\n",
    "        \"sortName\": \"code\",\n",
    "        \"sortType\": \"asc\",\n",
    "        \"isHLtitle\": \"false\"\n",
    "    }\n",
    "    return requests.post(url, data=data, headers=headers)\n",
    "\n",
    "\n",
    "def download_report(date):\n",
    "    global counter\n",
    "    all_results = []\n",
    "    page_num = 1\n",
    "    response_test = get_report(page_num, date)\n",
    "\n",
    "    try:\n",
    "        data_test = response_test.json()\n",
    "        total_pages = data_test.get(\"totalpages\", 0)\n",
    "        if total_pages == 0:\n",
    "            return all_results\n",
    "    except (ValueError, KeyError) as e:\n",
    "        print(f\"è·å–æ€»é¡µæ•°å¤±è´¥: {e}\")\n",
    "        return all_results\n",
    "\n",
    "    max_retries = 3\n",
    "    while page_num <= total_pages + 1:\n",
    "        retry_count = 0\n",
    "        while retry_count <= max_retries:\n",
    "            try:\n",
    "                response = get_report(page_num, date)\n",
    "                response.raise_for_status()\n",
    "                data = response.json()\n",
    "                if not data.get(\"announcements\"):\n",
    "                    break\n",
    "                all_results.extend(data[\"announcements\"])\n",
    "                if total_pages > 0:\n",
    "                    per = (counter / total_pages)\n",
    "                    if per < 1:\n",
    "                        print(f\"\\rå½“å‰å¹´ä»½ä¸‹è½½è¿›åº¦ {per * 100:.2f}%\", end='')\n",
    "                    else:\n",
    "                        print(f\"\\rä¸‹è½½å®Œæˆï¼Œæ­£åœ¨ä¿å­˜â€¦â€¦\", end='')\n",
    "                else:\n",
    "                    print(\"æ— æ³•è®¡ç®—ä¸‹è½½è¿›åº¦ï¼Œæ€»é¡µæ•°ä¸º0ã€‚\")\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(f\"ç¬¬{page_num}é¡µé”™è¯¯: {e}ï¼Œ5ç§’åé‡è¯•...\")\n",
    "                time.sleep(5)\n",
    "                retry_count += 1\n",
    "        page_num += 1\n",
    "        counter += 1\n",
    "    return all_results\n",
    "\n",
    "\n",
    "def main(year):\n",
    "    global sum\n",
    "    date_count = f\"{year}-01-01~{year}-12-31\"\n",
    "    response = get_report(1, date_count)\n",
    "    data = response.json()\n",
    "    sum = data.get(\"totalpages\", 0)\n",
    "\n",
    "    year += 1\n",
    "    all_results = []\n",
    "    time_segments = [\n",
    "        f\"{year}-01-01~{year}-04-01\",\n",
    "        f\"{year}-04-02~{year}-04-15\",\n",
    "        f\"{year}-04-16~{year}-04-22\",\n",
    "        f\"{year}-04-23~{year}-04-26\",\n",
    "        f\"{year}-04-27~{year}-04-28\",\n",
    "        f\"{year}-04-29~{year}-04-30\",\n",
    "        f\"{year}-05-01~{year}-07-31\",\n",
    "        f\"{year}-08-01~{year}-10-31\",\n",
    "        f\"{year}-11-01~{year}-11-30\",\n",
    "        f\"{year}-12-01~{year}-12-31\"\n",
    "    ]\n",
    "    for segment in time_segments:\n",
    "        all_results.extend(download_report(segment))\n",
    "\n",
    "    # ========== å¯é€‰ï¼šä¿ç•™æœ€æ–°ç‰ˆæœ¬å¹´æŠ¥ ==========\n",
    "\n",
    "    def filter_latest_versions(ans):\n",
    "        keywords = ['æ›´æ­£','æ›´æ­£å','æ›´æ­£ç‰ˆ','ä¿®è®¢å','ä¿®è®¢ç‰ˆ','æ›´æ–°å','æ›´æ–°ç‰ˆ']\n",
    "        latest = {}\n",
    "        for item in ans:\n",
    "            code = item['secCode']\n",
    "            m = re.search(r\"(\\d{4})å¹´\", item['announcementTitle'])\n",
    "            yr = m.group(1) if m else ''\n",
    "            key = (code, yr)\n",
    "            title = item['announcementTitle']\n",
    "            if key not in latest or (any(kw in title for kw in keywords) and not any(kw in latest[key]['announcementTitle'] for kw in keywords)):\n",
    "                latest[key] = item\n",
    "        return list(latest.values())\n",
    "    # å¯ç”¨ä¸‹è¡Œä»¥ä»…ä¿ç•™æ›´æ–°åå¹´æŠ¥\n",
    "    all_results = filter_latest_versions(all_results)\n",
    "    \n",
    "\n",
    "    workbook = openpyxl.Workbook()\n",
    "    ws = workbook.active\n",
    "    ws.title = \"å¹´æŠ¥\"\n",
    "    ws.append([\"å…¬å¸ä»£ç \", \"å…¬å¸ç®€ç§°\", \"æ ‡é¢˜\", \"å¹´ä»½\", \"å¹´æŠ¥é“¾æ¥\"])\n",
    "    for item in all_results:\n",
    "        company_code = item['secCode']\n",
    "        company_name = item['secName']\n",
    "        title = re.sub(r\"<.*?>\", \"\", item['announcementTitle'].strip()).replace('ï¼š','')\n",
    "        title = f\"ã€Š{title}ã€‹\"\n",
    "        m = re.search(r\"(\\d{4})å¹´\", title)\n",
    "        year_str = m.group(1) if m else setYear\n",
    "        url = f\"http://static.cninfo.com.cn/{item['adjunctUrl']}\"\n",
    "        if not any(kw in title for kw in exclude_keywords):\n",
    "            ws.append([company_code, company_name, title, year_str, url])\n",
    "\n",
    "    save_path = os.path.join(output_dir, f\"å¹´æŠ¥é“¾æ¥_{setYear}{GZH}.xlsx\")\n",
    "    workbook.save(save_path)\n",
    "    print(f\"å·²ä¿å­˜åˆ° {save_path}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # æ’é™¤åˆ—è¡¨å¯ä»¥åŠ å…¥'æ›´æ­£å','ä¿®è®¢ç‰ˆ'æ¥è§„é¿æ•°æ®é‡å¤æˆ–å…¬å¸å‘å¸ƒä¹‹å‰å¹´ä»½çš„å¹´æŠ¥ä¿®è®¢ç‰ˆç­‰é—®é¢˜ï¼Œ\n",
    "    exclude_keywords = ['è‹±æ–‡','å·²å–æ¶ˆ','æ‘˜è¦']\n",
    "    # æ§åˆ¶è¡Œä¸šï¼Œè‹¥ä¸ºç©ºåˆ™ä¸æ§åˆ¶ï¼Œä»…å¯ä»å‚è€ƒå†…å®¹ä¸­é€‰å–ï¼Œä¸­é—´ç”¨è‹±æ–‡åˆ†å·éš”å¼€\n",
    "    # å‚è€ƒå†…å®¹ï¼š\"å†œã€æ—ã€ç‰§ã€æ¸”ä¸š;ç”µåŠ›ã€çƒ­åŠ›ã€ç‡ƒæ°”åŠæ°´ç”Ÿäº§å’Œä¾›åº”ä¸š;å»ºç­‘ä¸š;é‡‡çŸ¿ä¸š;åˆ¶é€ ä¸š;æ‰¹å‘å’Œé›¶å”®ä¸š;äº¤é€šè¿è¾“ã€ä»“å‚¨å’Œé‚®æ”¿ä¸š;ä½å®¿å’Œé¤é¥®ä¸š;ä¿¡æ¯ä¼ è¾“ã€è½¯ä»¶å’Œä¿¡æ¯æŠ€æœ¯æœåŠ¡ä¸š;é‡‘èä¸š;æˆ¿åœ°äº§ä¸š;ç§Ÿèµå’Œå•†åŠ¡æœåŠ¡ä¸š;ç§‘å­¦ç ”ç©¶å’ŒæŠ€æœ¯æœåŠ¡ä¸š;æ°´åˆ©ã€ç¯å¢ƒå’Œå…¬å…±è®¾æ–½ç®¡ç†ä¸š;å±…æ°‘æœåŠ¡ã€ä¿®ç†å’Œå…¶ä»–æœåŠ¡ä¸š;æ•™è‚²;å«ç”Ÿå’Œç¤¾ä¼šå·¥ä½œ;æ–‡åŒ–ã€ä½“è‚²å’Œå¨±ä¹ä¸š;ç»¼åˆ\"\n",
    "    trade = \"\"\n",
    "    # æ¿å—æ§åˆ¶ï¼šæ·±å¸‚sz æ²ªå¸‚sh æ·±ä¸»æ¿szmb æ²ªä¸»æ¿shmb åˆ›ä¸šæ¿szcy ç§‘åˆ›æ¿shkcp åŒ—äº¤æ‰€bj è¯·æŒ‰ç…§æ ¼å¼å¡«å†™\n",
    "    plate = \"sz;sh\"\n",
    "    # ========= å¯é€‰è®¾ç½®ï¼šè‡ªå®šä¹‰å…¬å¸åˆ—è¡¨ï¼Œä»…ä¸‹è½½æŒ‡å®šå…¬å¸å¹´æŠ¥ =========\n",
    "    # ç¤ºä¾‹ï¼š['600519', '000001']ï¼Œç•™ç©ºåˆ™ä¸‹è½½å…¨éƒ¨\n",
    "    secCode = ['300500','000670']\n",
    "    # ç¤ºä¾‹ï¼š['ä¸­é›†é›†å›¢', 'ä¸­æ´²æ§è‚¡']ï¼Œç•™ç©ºåˆ™ä¸‹è½½å…¨éƒ¨\n",
    "    secName = []\n",
    "\n",
    "    global counter, sum\n",
    "    counter = 1\n",
    "    setYear = 2024\n",
    "    Flag = 0\n",
    "\n",
    "    def filter_excel(year):\n",
    "        if not secCode and not secName:\n",
    "            return\n",
    "        try:\n",
    "            src = os.path.join(output_dir, f\"å¹´æŠ¥é“¾æ¥_{year}{GZH}.xlsx\")\n",
    "            wb = openpyxl.load_workbook(src)\n",
    "            ws = wb.active\n",
    "            rows = list(ws.iter_rows(values_only=True))\n",
    "            header = rows[0]\n",
    "            filtered = [header] + [r for r in rows[1:] if str(r[0]) in secCode or str(r[1]) in secName]\n",
    "            wb_new = openpyxl.Workbook()\n",
    "            ws_new = wb_new.active\n",
    "            for r in filtered:\n",
    "                ws_new.append(r)\n",
    "            dst = os.path.join(output_dir, f\"å¹´æŠ¥é“¾æ¥_{year}_é€‰å–å…¬å¸.xlsx\")\n",
    "            wb_new.save(dst)\n",
    "            print(f\"è¿‡æ»¤å®Œæˆ: {dst} å·²ç”Ÿæˆ\")\n",
    "        except Exception as e:\n",
    "            print(f\"è¿‡æ»¤å¤±è´¥: {e}ï¼Œå·²è·³è¿‡\")\n",
    "\n",
    "    if Flag:\n",
    "        for y in range(2020, setYear+1):\n",
    "            counter = 1\n",
    "            main(y)\n",
    "            filter_excel(y)\n",
    "            print(f\"----{y}å¹´ä¸‹è½½å®Œæˆ\")\n",
    "    else:\n",
    "        main(setYear)\n",
    "        filter_excel(setYear)\n",
    "        print(f\"----{setYear}å¹´ä¸‹è½½å®Œæˆ\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-31 22:31:16] Reading Excel: /Users/sam/Desktop/cninfo_output/å¹´æŠ¥é“¾æ¥_2024_é€‰å–å…¬å¸.xlsx\n",
      "[2025-07-31 22:31:16] Found 2 records for 2024.\n",
      "[2025-07-31 22:31:17] Downloaded: /Users/sam/Desktop/cninfo_output/pdf_reports_2024/300500_å¯è¿ªè®¾è®¡_2024.pdf\n",
      "[2025-07-31 22:31:17] Downloaded: /Users/sam/Desktop/cninfo_output/pdf_reports_2024/670_ç›ˆæ–¹å¾®_2024.pdf\n",
      "[2025-07-31 22:31:17] All downloads completed in 0.49s. PDFs saved to: /Users/sam/Desktop/cninfo_output/pdf_reports_2024\n"
     ]
    }
   ],
   "source": [
    "### æœ‰#pdfè½¬ç çš„éƒ¨åˆ†\n",
    "\n",
    "#!/usr/bin/env python\n",
    "# -*- coding: UTF-8 -*-\n",
    "'''\n",
    "@Project ï¼šPycharmProjects\n",
    "@File    ï¼šå¹´æŠ¥æ‰¹é‡ä¸‹è½½_ä¼˜åŒ–.py\n",
    "@IDE     ï¼šPyCharm\n",
    "@Author  ï¼šlingxiaotian\n",
    "@Modified: ä»…ä¸‹è½½ PDFã€å¤šçº¿ç¨‹åŠ é€Ÿã€ä¿ç•™ TXT è½¬æ¢ç¤ºä¾‹ï¼ˆæ³¨é‡Šï¼‰\n",
    "@Date    ï¼š2023/05/30\n",
    "'''\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "import os\n",
    "import re\n",
    "import logging\n",
    "from datetime import datetime\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "# æ—¥å¿—é…ç½®\n",
    "logging.basicConfig(level=logging.INFO, format='[%(asctime)s] %(message)s')\n",
    "\n",
    "def log(msg):\n",
    "    print(f\"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] {msg}\")\n",
    "\n",
    "# å‚æ•°é…ç½®\n",
    "BASE_DIR    = os.path.expanduser(\"~/Desktop/cninfo_output\")\n",
    "EXCEL_FILE  = os.path.join(BASE_DIR, \"å¹´æŠ¥é“¾æ¥_2024_é€‰å–å…¬å¸.xlsx\")\n",
    "PDF_DIR     = os.path.join(BASE_DIR, \"pdf_reports_2024\")\n",
    "MAX_WORKERS = 16  # å¹¶å‘çº¿ç¨‹æ•°ï¼Œå¯æ ¹æ®ç½‘ç»œæƒ…å†µè°ƒæ•´\n",
    "\n",
    "# ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨\n",
    "os.makedirs(PDF_DIR, exist_ok=True)\n",
    "\n",
    "# ä¸‹è½½å•ä¸ª PDF\n",
    "def download_pdf(record):\n",
    "    code, name, year, url = record\n",
    "    safe = re.sub(r'[\\\\/:*?\"<>|]', '', f\"{code}_{name}_{year}\")\n",
    "    path = os.path.join(PDF_DIR, f\"{safe}.pdf\")\n",
    "    if os.path.exists(path):\n",
    "        log(f\"Exists, skip: {path}\")\n",
    "        return\n",
    "    try:\n",
    "        resp = requests.get(url, timeout=15)\n",
    "        content_type = resp.headers.get(\"Content-Type\", \"\").lower()\n",
    "        if resp.status_code == 200 and \"pdf\" in content_type:\n",
    "            with open(path, 'wb') as f:\n",
    "                f.write(resp.content)\n",
    "            log(f\"Downloaded: {path}\")\n",
    "        else:\n",
    "            log(f\"Failed ({resp.status_code}) or not PDF: {url}\")\n",
    "    except Exception as e:\n",
    "        log(f\"Error downloading {url}: {e}\")\n",
    "\n",
    "# ========== TXT è½¬æ¢ç¤ºä¾‹ï¼ˆæš‚ä¸æ‰§è¡Œï¼‰ ==========\n",
    "'''\n",
    "import pdfplumber\n",
    "\n",
    "def convert_to_txt(pdf_path, txt_path):\n",
    "    try:\n",
    "        with pdfplumber.open(pdf_path) as pdf, open(txt_path, 'w', encoding='utf-8') as f:\n",
    "            for page in pdf.pages:\n",
    "                f.write(page.extract_text() or '')\n",
    "        log(f\"TXT saved: {txt_path}\")\n",
    "    except Exception as e:\n",
    "        log(f\"TXT conversion error: {e} - {pdf_path}\")\n",
    "'''\n",
    "\n",
    "# ä¸»æµç¨‹\n",
    "def main():\n",
    "    log(f\"Reading Excel: {EXCEL_FILE}\")\n",
    "    if not os.path.exists(EXCEL_FILE):\n",
    "        log(\"Excel file not found. è¯·æ£€æŸ¥è·¯å¾„ã€‚\")\n",
    "        return\n",
    "    df = pd.read_excel(EXCEL_FILE)\n",
    "    records = [\n",
    "        (r['å…¬å¸ä»£ç '], r['å…¬å¸ç®€ç§°'], r['å¹´ä»½'], r['å¹´æŠ¥é“¾æ¥'])\n",
    "        for _, r in df.iterrows()\n",
    "        if str(r.get('å¹´ä»½')) == '2024'\n",
    "    ]\n",
    "    log(f\"Found {len(records)} records for 2024.\")\n",
    "\n",
    "    start = datetime.now()\n",
    "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
    "        futures = [executor.submit(download_pdf, rec) for rec in records]\n",
    "        for future in as_completed(futures):\n",
    "            pass\n",
    "    elapsed = (datetime.now() - start).total_seconds()\n",
    "    log(f\"All downloads completed in {elapsed:.2f}s. PDFs saved to: {PDF_DIR}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in /Users/sam/Library/Python/3.9/lib/python/site-packages (2.2.3)\n",
      "Requirement already satisfied: requests in /Users/sam/Library/Python/3.9/lib/python/site-packages (2.32.3)\n",
      "Requirement already satisfied: openpyxl in /Users/sam/Library/Python/3.9/lib/python/site-packages (3.1.5)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /Users/sam/Library/Python/3.9/lib/python/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/sam/Library/Python/3.9/lib/python/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/sam/Library/Python/3.9/lib/python/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/sam/Library/Python/3.9/lib/python/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/sam/Library/Python/3.9/lib/python/site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/sam/Library/Python/3.9/lib/python/site-packages (from requests) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/sam/Library/Python/3.9/lib/python/site-packages (from requests) (2024.8.30)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/sam/Library/Python/3.9/lib/python/site-packages (from requests) (3.4.0)\n",
      "Requirement already satisfied: et-xmlfile in /Users/sam/Library/Python/3.9/lib/python/site-packages (from openpyxl) (2.0.0)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas) (1.15.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.1.1 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas requests openpyxl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ‘‰ æ­£è‚¡æ˜ å°„å·²å®Œæˆï¼Œç»“æœä¿å­˜åœ¨ï¼š /Users/sam/Desktop/æ­£è‚¡æ˜ å°„ç»“æœ.xlsx\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "from time import sleep\n",
    "\n",
    "def get_underlying_stock(bond_code):\n",
    "    \"\"\"\n",
    "    ç”¨ä¸œæ–¹è´¢å¯Œå¯è½¬å€ºåˆ—è¡¨æ¥å£ï¼Œä¼ å…¥å¯è½¬å€ºä»£ç ï¼ˆä¸å¸¦åç¼€ï¼‰ï¼Œ\n",
    "    è¿”å›ï¼šæ­£è‚¡ä»£ç ï¼ˆå¸¦åç¼€ï¼‰å’Œæ­£è‚¡åç§°\n",
    "    \"\"\"\n",
    "    url = (\n",
    "        \"https://datacenter-web.eastmoney.com/api/data/v1/get\"\n",
    "        \"?reportName=RPT_BOND_CB_LIST\"\n",
    "        \"&columns=SECUCODE,SECURITY_NAME_ABBR,UNDERLYING_SECURITY_CODE,UNDERLYING_SECURITY_NAME\"\n",
    "        f\"&filter=(SECUCODE='{bond_code}')\"\n",
    "    )\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "    try:\n",
    "        resp = requests.get(url, headers=headers, timeout=10)\n",
    "        # å¦‚æœè¯·æ±‚ä¸æˆåŠŸï¼Œç›´æ¥è¿”å›ç©º\n",
    "        if not resp.ok:\n",
    "            return None, None\n",
    "\n",
    "        # å°è¯•è§£æ JSON\n",
    "        data = resp.json()\n",
    "    except (requests.RequestException, ValueError):\n",
    "        # ç½‘ç»œé—®é¢˜æˆ– JSON è§£æå¤±è´¥\n",
    "        return None, None\n",
    "\n",
    "    # ä¸‹é¢å¼€å§‹å®‰å…¨åœ°ä» data ä¸­å–å€¼\n",
    "    result = data.get(\"result\")\n",
    "    if not result:\n",
    "        return None, None\n",
    "\n",
    "    items = result.get(\"data\")\n",
    "    if not items:\n",
    "        return None, None\n",
    "\n",
    "    d = items[0]\n",
    "    code = d.get(\"UNDERLYING_SECURITY_CODE\", \"\")\n",
    "    name = d.get(\"UNDERLYING_SECURITY_NAME\", \"\")\n",
    "\n",
    "    # åˆ¤æ–­äº¤æ˜“æ‰€åç¼€\n",
    "    suffix = \".SH\" if code.startswith((\"60\", \"68\")) else \".SZ\"\n",
    "    return code + suffix, name\n",
    "\n",
    "def main():\n",
    "    # 1. æ–‡ä»¶è·¯å¾„ï¼ˆæ›¿æ¢æˆä½ çœŸå®ç”¨æˆ·åï¼Œå¦‚æœéœ€è¦ä¹Ÿå¯æ”¹æˆç»å¯¹è·¯å¾„ï¼‰\n",
    "    input_path  = os.path.expanduser(\"~/Desktop/è¡Œæƒ…ä¸åˆ†æ20250605.xlsx\")\n",
    "    output_path = os.path.expanduser(\"~/Desktop/æ­£è‚¡æ˜ å°„ç»“æœ.xlsx\")\n",
    "\n",
    "    # 2. è¯»å– Excel\n",
    "    df = pd.read_excel(input_path, dtype=str)\n",
    "\n",
    "    # 3. æ–°å¢ä¸¤åˆ—\n",
    "    df[\"æ­£è‚¡ä»£ç \"] = \"\"\n",
    "    df[\"æ­£è‚¡åç§°\"] = \"\"\n",
    "\n",
    "    # 4. å¾ªç¯æŸ¥è¯¢\n",
    "    for idx, row in df.iterrows():\n",
    "        bond = row.get(\"ä»£ç \", \"\")\n",
    "        if not isinstance(bond, str) or \".\" not in bond:\n",
    "            # è·³è¿‡æ ¼å¼å¼‚å¸¸çš„è¡Œ\n",
    "            continue\n",
    "\n",
    "        bond_code = bond.split(\".\")[0]\n",
    "        stock_code, stock_name = get_underlying_stock(bond_code)\n",
    "\n",
    "        df.at[idx, \"æ­£è‚¡ä»£ç \"] = stock_code or \"\"\n",
    "        df.at[idx, \"æ­£è‚¡åç§°\"] = stock_name or \"\"\n",
    "        sleep(0.3)   # é¿å…è¢«æ¥å£é™æµ\n",
    "\n",
    "    # 5. ä¿å­˜ç»“æœ\n",
    "    df.to_excel(output_path, index=False, engine=\"openpyxl\")\n",
    "    print(\"ğŸ‘‰ æ­£è‚¡æ˜ å°„å·²å®Œæˆï¼Œç»“æœä¿å­˜åœ¨ï¼š\", output_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in /Users/sam/Library/Python/3.9/lib/python/site-packages (2.2.3)\n",
      "Requirement already satisfied: requests in /Users/sam/Library/Python/3.9/lib/python/site-packages (2.32.3)\n",
      "Requirement already satisfied: openpyxl in /Users/sam/Library/Python/3.9/lib/python/site-packages (3.1.5)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/sam/Library/Python/3.9/lib/python/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /Users/sam/Library/Python/3.9/lib/python/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/sam/Library/Python/3.9/lib/python/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/sam/Library/Python/3.9/lib/python/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/sam/Library/Python/3.9/lib/python/site-packages (from requests) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/sam/Library/Python/3.9/lib/python/site-packages (from requests) (2024.8.30)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/sam/Library/Python/3.9/lib/python/site-packages (from requests) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/sam/Library/Python/3.9/lib/python/site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: et-xmlfile in /Users/sam/Library/Python/3.9/lib/python/site-packages (from openpyxl) (2.0.0)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas) (1.15.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.1.1 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas requests openpyxl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3159610652.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[6], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    python3 bond_to_stock.py\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "python3 bond_to_stock.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
