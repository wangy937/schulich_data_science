{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sam/Library/Python/3.9/lib/python/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 正股映射已完成，结果保存在： /Users/sam/Desktop/正股映射结果.xlsx\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import efinance as ef       # pip install efinance\n",
    "\n",
    "def main():\n",
    "    # 1. 定位文件\n",
    "    in_file  = os.path.expanduser(\"~/Desktop/行情与分析20250605.xlsx\")\n",
    "    out_file = os.path.expanduser(\"~/Desktop/正股映射结果.xlsx\")\n",
    "\n",
    "    # 2. 读取原始 Excel\n",
    "    df_raw = pd.read_excel(in_file, dtype=str)  # 支持 .xlsx/.xls 等格式 :contentReference[oaicite:8]{index=8}\n",
    "\n",
    "    # 3. 拉取全市场可转债基础信息\n",
    "    #    包含字段：债券代码、债券名称、正股代码、正股名称、...... :contentReference[oaicite:9]{index=9}\n",
    "    df_all = ef.bond.get_all_base_info()\n",
    "\n",
    "    # 4. 清洗字段：提取无后缀的可转债 code 和纯数字正股 code/name\n",
    "    df_all[\"bond_code\"]  = df_all[\"债券代码\"].astype(str).str.strip()       # e.g. '110059' :contentReference[oaicite:10]{index=10}\n",
    "    df_all[\"stock_code\"] = df_all[\"正股代码\"].astype(str).str.strip()       # e.g. '600000' :contentReference[oaicite:11]{index=11}\n",
    "    df_all[\"stock_name\"] = df_all[\"正股名称\"].astype(str).str.strip()       # e.g. '浦发银行' :contentReference[oaicite:12]{index=12}\n",
    "\n",
    "    # 5. 原表中提取 bond_code（去掉 '.SH'/'.SZ' 后缀）\n",
    "    df_raw[\"bond_code\"] = df_raw[\"代码\"].str.split(\".\").str[0]\n",
    "\n",
    "    # 6. 左合并：把正股信息映射到原表\n",
    "    df_merged = df_raw.merge(\n",
    "        df_all[[\"bond_code\", \"stock_code\", \"stock_name\"]],\n",
    "        on=\"bond_code\", how=\"left\"\n",
    "    )\n",
    "\n",
    "    # 7. 构造最终列：带后缀的正股代码 + 正股名称\n",
    "    def add_suffix(code: str) -> str:\n",
    "        if not isinstance(code, str) or not code.isdigit():\n",
    "            return \"\"\n",
    "        return code + (\".SH\" if code.startswith((\"60\",\"68\")) else \".SZ\")\n",
    "\n",
    "    df_merged[\"正股代码\"] = df_merged[\"stock_code\"].apply(add_suffix)\n",
    "    df_merged[\"正股名称\"] = df_merged[\"stock_name\"].fillna(\"\")\n",
    "\n",
    "    # 8. 删除中间列并保存到 Excel\n",
    "    df_final = df_merged.drop(columns=[\"bond_code\", \"stock_code\", \"stock_name\"])\n",
    "    df_final.to_excel(out_file, index=False, engine=\"openpyxl\")  # 支持写入 .xlsx :contentReference[oaicite:13]{index=13}\n",
    "\n",
    "    print(\"✅ 正股映射已完成，结果保存在：\", out_file)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已保存：/Users/sam/Desktop/cninfo_output/年报链接_2024_选取公司【年报】.xlsx，共 469 条链接\n",
      "---- 2024 年下载完成 ----\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import requests\n",
    "import openpyxl\n",
    "import pandas as pd\n",
    "\n",
    "# —— 配置区 —— \n",
    "YEAR = 2024                           # 目标年份\n",
    "GZH  = f\"【年报】\"\n",
    "exclude_keywords = ['英文', '已取消', '摘要']\n",
    "trade = \"\"                            # 行业过滤，不需要则留空\n",
    "plate = \"\"                            # 板块过滤，不需要则留空\n",
    "\n",
    "# 输出目录\n",
    "output_dir = os.path.expanduser(\"~/Desktop/cninfo_output\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# 正股映射表路径（第一部分脚本生成）\n",
    "mapping_file = os.path.expanduser(\"~/Desktop/正股映射结果.xlsx\")\n",
    "\n",
    "def get_report(page_num: int, date_range: str) -> requests.Response:\n",
    "    \"\"\"\n",
    "    调用巨潮网历史公告查询接口\n",
    "    \"\"\"\n",
    "    url = \"http://www.cninfo.com.cn/new/hisAnnouncement/query\"\n",
    "    headers = {\n",
    "        \"Accept\": \"*/*\",\n",
    "        \"Accept-Encoding\": \"gzip, deflate\",\n",
    "        \"Accept-Language\": \"zh-CN,zh;q=0.9\",\n",
    "        \"Content-Type\": \"application/x-www-form-urlencoded; charset=UTF-8\",\n",
    "        \"Origin\": \"http://www.cninfo.com.cn\",\n",
    "        \"Referer\": (\n",
    "            \"http://www.cninfo.com.cn/new/commonUrl/\"\n",
    "            \"pageOfSearch?url=disclosure/list/search\"\n",
    "            \"&checkedCategory=category_ndbg_szsh\"\n",
    "        ),\n",
    "        \"User-Agent\": \"Mozilla/5.0\",\n",
    "        \"X-Requested-With\": \"XMLHttpRequest\"\n",
    "    }\n",
    "    payload = {\n",
    "        \"pageNum\": page_num,\n",
    "        \"pageSize\": 30,\n",
    "        \"column\": \"szse\",\n",
    "        \"tabName\": \"fulltext\",\n",
    "        \"plate\": plate,\n",
    "        \"searchkey\": \"\",\n",
    "        \"secid\": \"\",\n",
    "        \"category\": \"category_ndbg_szsh\",\n",
    "        \"trade\": trade,\n",
    "        \"seDate\": date_range,\n",
    "        \"sortName\": \"code\",\n",
    "        \"sortType\": \"asc\",\n",
    "        \"isHLtitle\": \"false\"\n",
    "    }\n",
    "    return requests.post(url, data=payload, headers=headers)\n",
    "\n",
    "def download_report(date_range: str) -> list[dict]:\n",
    "    \"\"\"\n",
    "    分页下载单个时间段内的所有公告\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    page = 1\n",
    "    resp = get_report(page, date_range)\n",
    "    try:\n",
    "        total_pages = resp.json().get(\"totalpages\", 0)\n",
    "    except Exception:\n",
    "        return results\n",
    "    if total_pages == 0:\n",
    "        return results\n",
    "\n",
    "    while page <= total_pages:\n",
    "        for attempt in range(3):\n",
    "            resp = get_report(page, date_range)\n",
    "            try:\n",
    "                resp.raise_for_status()\n",
    "                ann = resp.json().get(\"announcements\", [])\n",
    "                if ann:\n",
    "                    results.extend(ann)\n",
    "                break\n",
    "            except Exception:\n",
    "                time.sleep(5)\n",
    "        page += 1\n",
    "\n",
    "    return results\n",
    "\n",
    "def filter_latest_versions(announcements: list[dict]) -> list[dict]:\n",
    "    \"\"\"\n",
    "    同一公司同一年只保留最新“更正/修订”版本\n",
    "    \"\"\"\n",
    "    rev_kws = ['更正','更正后','更正版','修订后','修订版','更新后','更新版']\n",
    "    latest = {}\n",
    "    for item in announcements:\n",
    "        sec  = item['secCode']\n",
    "        title= item['announcementTitle']\n",
    "        year_match = re.search(r\"(\\d{4})年\", title)\n",
    "        year_str   = year_match.group(1) if year_match else \"\"\n",
    "        key = (sec, year_str)\n",
    "        if key not in latest:\n",
    "            latest[key] = item\n",
    "        else:\n",
    "            curr = latest[key]['announcementTitle']\n",
    "            # 新条目若为修订版，且已有条目不是，则替换\n",
    "            if any(kw in title for kw in rev_kws) and not any(kw in curr for kw in rev_kws):\n",
    "                latest[key] = item\n",
    "    return list(latest.values())\n",
    "\n",
    "def download_reports_for_year(year: int) -> list[dict]:\n",
    "    \"\"\"\n",
    "    抓取上一年发布的年度报告公告：\n",
    "    1) 主时间段：year-01-01~year-12-31\n",
    "    2) 次年分段：year+1 的若干子区间\n",
    "    \"\"\"\n",
    "    # 次年分段，以捕获跨年发布时间\n",
    "    ny = year + 1\n",
    "    segments = [\n",
    "        f\"{ny}-01-01~{ny}-04-01\", f\"{ny}-04-02~{ny}-04-15\",\n",
    "        f\"{ny}-04-16~{ny}-04-22\", f\"{ny}-04-23~{ny}-04-26\",\n",
    "        f\"{ny}-04-27~{ny}-04-28\", f\"{ny}-04-29~{ny}-04-30\",\n",
    "        f\"{ny}-05-01~{ny}-07-31\", f\"{ny}-08-01~{ny}-10-31\",\n",
    "        f\"{ny}-11-01~{ny}-11-30\", f\"{ny}-12-01~{ny}-12-31\"\n",
    "    ]\n",
    "\n",
    "    all_ann = []\n",
    "    for seg in segments:\n",
    "        all_ann.extend(download_report(seg))\n",
    "\n",
    "    # 排除含有摘要等关键词的公告\n",
    "    filtered = [\n",
    "        x for x in all_ann\n",
    "        if not any(kw in x['announcementTitle'] for kw in exclude_keywords)\n",
    "    ]\n",
    "    return filter_latest_versions(filtered)\n",
    "\n",
    "def write_selected_excel(announcements: list[dict], year: int) -> None:\n",
    "    \"\"\"\n",
    "    只输出映射表中正股对应公司的年报链接\n",
    "    \"\"\"\n",
    "    # 读取映射表，提取无后缀的正股代码\n",
    "    df_map = pd.read_excel(mapping_file, dtype=str)\n",
    "    codes  = df_map['正股代码'].str.split('.').str[0].tolist()\n",
    "\n",
    "    wb = openpyxl.Workbook()\n",
    "    ws = wb.active\n",
    "    ws.title = f\"{year}年报\"\n",
    "    ws.append([\"可转债正股代码\", \"公司简称\", \"标题\", \"年份\", \"年报链接\"])\n",
    "    for it in announcements:\n",
    "        sec = it[\"secCode\"]\n",
    "        if sec not in codes:\n",
    "            continue\n",
    "        name      = it[\"secName\"]\n",
    "        raw_title = re.sub(r\"<.*?>\", \"\", it[\"announcementTitle\"]).replace(\"：\", \"\")\n",
    "        title     = f\"《{raw_title}》\"\n",
    "        ym        = re.search(r\"(\\d{4})年\", raw_title)\n",
    "        yr        = ym.group(1) if ym else \"\"\n",
    "        url       = f\"http://static.cninfo.com.cn/{it['adjunctUrl']}\"\n",
    "        ws.append([sec, name, title, yr, url])\n",
    "\n",
    "    dst = os.path.join(output_dir, f\"年报链接_{year}_选取公司{GZH}.xlsx\")\n",
    "    wb.save(dst)\n",
    "    print(f\"已保存：{dst}，共 {ws.max_row-1} 条链接\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 抓取并过滤\n",
    "    all_ann = download_reports_for_year(YEAR)\n",
    "    write_selected_excel(all_ann, YEAR)\n",
    "    print(f\"---- {YEAR} 年下载完成 ----\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 已保存：/Users/sam/Desktop/cninfo_output/年报链接_2024_选取公司【年报】.xlsx  （共 472 条链接）\n",
      "---- 2024 年下载完成 ----\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import requests\n",
    "import openpyxl\n",
    "import pandas as pd\n",
    "\n",
    "# —— 参数配置 —— \n",
    "YEAR = 2024                           # 目标年份\n",
    "GZH  = \"【年报】\"\n",
    "exclude_keywords = ['英文', '已取消', '摘要']\n",
    "trade = \"\"                            # 行业过滤，不需要则留空\n",
    "plate = \"\"                            # 板块过滤，不需要则留空\n",
    "\n",
    "# 输出目录\n",
    "output_dir = os.path.expanduser(\"~/Desktop/cninfo_output\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# 正股映射表路径（第一部分脚本生成）\n",
    "mapping_file = os.path.expanduser(\"~/Desktop/正股映射结果.xlsx\")\n",
    "\n",
    "\n",
    "def get_report(page_num: int, date_range: str) -> requests.Response:\n",
    "    \"\"\"调用巨潮网历史公告查询接口\"\"\"\n",
    "    url = \"http://www.cninfo.com.cn/new/hisAnnouncement/query\"\n",
    "    headers = {\n",
    "        \"Accept\": \"*/*\",\n",
    "        \"Accept-Encoding\": \"gzip, deflate\",\n",
    "        \"Accept-Language\": \"zh-CN,zh;q=0.9\",\n",
    "        \"Content-Type\": \"application/x-www-form-urlencoded; charset=UTF-8\",\n",
    "        \"Origin\": \"http://www.cninfo.com.cn\",\n",
    "        \"Referer\": (\n",
    "            \"http://www.cninfo.com.cn/new/commonUrl/\"\n",
    "            \"pageOfSearch?url=disclosure/list/search\"\n",
    "            \"&checkedCategory=category_ndbg_szsh\"\n",
    "        ),\n",
    "        \"User-Agent\": \"Mozilla/5.0\",\n",
    "        \"X-Requested-With\": \"XMLHttpRequest\"\n",
    "    }\n",
    "    payload = {\n",
    "        \"pageNum\": page_num,\n",
    "        \"pageSize\": 30,\n",
    "        \"column\": \"szse\",    # 如果需要同时搜沪深，可循环 [\"szse\",\"shse\"]\n",
    "        \"tabName\": \"fulltext\",\n",
    "        \"plate\": plate,\n",
    "        \"searchkey\": \"\",\n",
    "        \"secid\": \"\",\n",
    "        \"category\": \"category_ndbg_szsh\",\n",
    "        \"trade\": trade,\n",
    "        \"seDate\": date_range,\n",
    "        \"sortName\": \"code\",\n",
    "        \"sortType\": \"asc\",\n",
    "        \"isHLtitle\": \"false\"\n",
    "    }\n",
    "    return requests.post(url, data=payload, headers=headers)\n",
    "\n",
    "\n",
    "def download_report(date_range: str) -> list[dict]:\n",
    "    \"\"\"分页下载单个时间段内的所有公告\"\"\"\n",
    "    results = []\n",
    "    page = 1\n",
    "    resp = get_report(page, date_range)\n",
    "    try:\n",
    "        total_pages = resp.json().get(\"totalpages\", 0)\n",
    "    except Exception:\n",
    "        return results\n",
    "    if total_pages == 0:\n",
    "        return results\n",
    "\n",
    "    while page <= total_pages:\n",
    "        for _ in range(3):\n",
    "            resp = get_report(page, date_range)\n",
    "            try:\n",
    "                resp.raise_for_status()\n",
    "                ann = resp.json().get(\"announcements\", [])\n",
    "                if ann:\n",
    "                    results.extend(ann)\n",
    "                break\n",
    "            except Exception:\n",
    "                time.sleep(5)\n",
    "        page += 1\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def filter_latest_versions(anns: list[dict]) -> list[dict]:\n",
    "    \"\"\"同一公司同一年只保留最新“更正/修订”版本\"\"\"\n",
    "    rev_kws = ['更正','更正后','更正版','修订后','修订版','更新后','更新版']\n",
    "    latest = {}\n",
    "    for it in anns:\n",
    "        sec = it['secCode']\n",
    "        title = it['announcementTitle']\n",
    "        ym = re.search(r\"(\\d{4})年\", title)\n",
    "        yr = ym.group(1) if ym else \"\"\n",
    "        key = (sec, yr)\n",
    "        if key not in latest:\n",
    "            latest[key] = it\n",
    "        else:\n",
    "            curr = latest[key]['announcementTitle']\n",
    "            # 如果本条为修订版，而已有条目不是，则替换\n",
    "            if any(kw in title for kw in rev_kws) and not any(kw in curr for kw in rev_kws):\n",
    "                latest[key] = it\n",
    "    return list(latest.values())\n",
    "\n",
    "\n",
    "def download_reports_for_year(year: int) -> list[dict]:\n",
    "    \"\"\"\n",
    "    抓取目标年份的年度报告公告：\n",
    "     1) year 全年（捕获当年整年公告）\n",
    "     2) year+1 分段 （捕获跨年发布）\n",
    "    \"\"\"\n",
    "    # 主时间段（可不用请求，只做分段足够）\n",
    "    # main_range = f\"{year}-01-01~{year}-12-31\"\n",
    "    # 次年分段，以捕获跨年发布时间\n",
    "    ny = year + 1\n",
    "    segments = [\n",
    "        f\"{ny}-01-01~{ny}-04-01\", f\"{ny}-04-02~{ny}-04-15\",\n",
    "        f\"{ny}-04-16~{ny}-04-22\", f\"{ny}-04-23~{ny}-04-26\",\n",
    "        f\"{ny}-04-27~{ny}-04-28\", f\"{ny}-04-29~{ny}-04-30\",\n",
    "        f\"{ny}-05-01~{ny}-07-31\", f\"{ny}-08-01~{ny}-10-31\",\n",
    "        f\"{ny}-11-01~{ny}-11-30\", f\"{ny}-12-01~{ny}-12-31\"\n",
    "    ]\n",
    "    all_ann = []\n",
    "    for seg in segments:\n",
    "        all_ann.extend(download_report(seg))\n",
    "\n",
    "    # 排除包含无用关键词的公告\n",
    "    filtered = [\n",
    "        x for x in all_ann\n",
    "        if not any(kw in x['announcementTitle'] for kw in exclude_keywords)\n",
    "    ]\n",
    "    return filter_latest_versions(filtered)\n",
    "\n",
    "\n",
    "def write_selected_excel(anns: list[dict], year: int) -> None:\n",
    "    \"\"\"\n",
    "    根据映射表顺序，输出可转债→正股的年报链接\n",
    "    \"\"\"\n",
    "    # 读取映射表\n",
    "    df_map = pd.read_excel(mapping_file, dtype=str)\n",
    "    # 确保映射表顺序与原表一致\n",
    "    df_map['sec_no_suf'] = df_map['正股代码'].str.split('.').str[0]\n",
    "\n",
    "    # 把公告列表按 secCode 建字典，便于快速查找\n",
    "    ann_dict = { it['secCode']: it for it in anns }\n",
    "\n",
    "    # 准备写表\n",
    "    wb = openpyxl.Workbook()\n",
    "    ws = wb.active\n",
    "    ws.title = f\"{year}年报\"\n",
    "    ws.append([\n",
    "        \"可转债代码\", \"可转债名称\",\n",
    "        \"公司代码\", \"公司简称\",\n",
    "        \"标题\", \"年份\", \"年报链接\"\n",
    "    ])\n",
    "\n",
    "    # 按映射表原始顺序输出\n",
    "    count = 0\n",
    "    for _, row in df_map.iterrows():\n",
    "        bond_code = row['代码']\n",
    "        bond_name = row.get('名称', \"\")\n",
    "        sec = row['sec_no_suf']\n",
    "        if sec not in ann_dict:\n",
    "            continue\n",
    "        it = ann_dict[sec]\n",
    "        raw = re.sub(r\"<.*?>\", \"\", it['announcementTitle']).replace(\"：\", \"\")\n",
    "        title = f\"《{raw}》\"\n",
    "        ym = re.search(r\"(\\d{4})年\", raw)\n",
    "        yr = ym.group(1) if ym else \"\"\n",
    "        url = f\"http://static.cninfo.com.cn/{it['adjunctUrl']}\"\n",
    "\n",
    "        ws.append([bond_code, bond_name, sec, it['secName'], title, yr, url])\n",
    "        count += 1\n",
    "\n",
    "    dst = os.path.join(output_dir, f\"年报链接_{year}_选取公司{GZH}.xlsx\")\n",
    "    wb.save(dst)\n",
    "    print(f\"✅ 已保存：{dst}  （共 {count} 条链接）\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 1) 抓取公告并过滤\n",
    "    all_ann = download_reports_for_year(YEAR)\n",
    "    # 2) 按映射表顺序写出最终选取公司年报链接\n",
    "    write_selected_excel(all_ann, YEAR)\n",
    "    print(f\"---- {YEAR} 年下载完成 ----\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 已保存：/Users/sam/Desktop/cninfo_output/年报链接_2024_选取公司【年报】.xlsx （共 472 条链接）\n",
      "---- 2024 年下载完成 ----\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import requests\n",
    "import openpyxl\n",
    "import pandas as pd\n",
    "\n",
    "# —— 参数配置 —— \n",
    "YEAR = 2024                           # 目标年份\n",
    "GZH  = \"【年报】\"\n",
    "exclude_keywords = ['英文', '已取消', '摘要']\n",
    "# 行业过滤、不需要可留空\n",
    "trade = \"\"\n",
    "# 板块过滤、不需要可留空\n",
    "plate = \"\"\n",
    "\n",
    "# 输出目录\n",
    "output_dir = os.path.expanduser(\"~/Desktop/cninfo_output\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# 第一部分脚本生成的正股映射表路径\n",
    "mapping_file = os.path.expanduser(\"~/Desktop/正股映射结果.xlsx\")\n",
    "\n",
    "# 全局 market 列（在主流程里切换 szse / shse）\n",
    "column = \"szse\"\n",
    "\n",
    "\n",
    "def get_report(page_num: int, date_range: str) -> requests.Response:\n",
    "    \"\"\"调用巨潮网历史公告查询接口\"\"\"\n",
    "    url = \"http://www.cninfo.com.cn/new/hisAnnouncement/query\"\n",
    "    headers = {\n",
    "        \"Accept\": \"*/*\",\n",
    "        \"Accept-Encoding\": \"gzip, deflate\",\n",
    "        \"Accept-Language\": \"zh-CN,zh;q=0.9\",\n",
    "        \"Content-Type\": \"application/x-www-form-urlencoded; charset=UTF-8\",\n",
    "        \"Origin\": \"http://www.cninfo.com.cn\",\n",
    "        \"Referer\": (\n",
    "            \"http://www.cninfo.com.cn/new/commonUrl/\"\n",
    "            \"pageOfSearch?url=disclosure/list/search\"\n",
    "            \"&checkedCategory=category_ndbg_szsh\"\n",
    "        ),\n",
    "        \"User-Agent\": \"Mozilla/5.0\",\n",
    "        \"X-Requested-With\": \"XMLHttpRequest\"\n",
    "    }\n",
    "    payload = {\n",
    "        \"pageNum\": page_num,\n",
    "        \"pageSize\": 30,\n",
    "        \"column\": column,\n",
    "        \"tabName\": \"fulltext\",\n",
    "        \"plate\": plate,\n",
    "        \"searchkey\": \"\",\n",
    "        \"secid\": \"\",\n",
    "        \"category\": \"category_ndbg_szsh\",\n",
    "        \"trade\": trade,\n",
    "        \"seDate\": date_range,\n",
    "        \"sortName\": \"code\",\n",
    "        \"sortType\": \"asc\",\n",
    "        \"isHLtitle\": \"false\"\n",
    "    }\n",
    "    return requests.post(url, data=payload, headers=headers)\n",
    "\n",
    "\n",
    "def download_report(date_range: str) -> list[dict]:\n",
    "    \"\"\"分页下载单个时间段内的公告列表\"\"\"\n",
    "    results = []\n",
    "    page = 1\n",
    "    try:\n",
    "        total_pages = get_report(1, date_range).json().get(\"totalpages\", 0)\n",
    "    except Exception:\n",
    "        return results\n",
    "    if total_pages == 0:\n",
    "        return results\n",
    "\n",
    "    while page <= total_pages:\n",
    "        for _ in range(3):\n",
    "            resp = get_report(page, date_range)\n",
    "            try:\n",
    "                resp.raise_for_status()\n",
    "                ann = resp.json().get(\"announcements\", [])\n",
    "                if ann:\n",
    "                    results.extend(ann)\n",
    "                break\n",
    "            except Exception:\n",
    "                time.sleep(5)\n",
    "        page += 1\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def filter_latest_versions(anns: list[dict]) -> list[dict]:\n",
    "    \"\"\"同一公司同一年只保留最新“更正/修订”版本\"\"\"\n",
    "    rev_kws = ['更正','更正后','更正版','修订后','修订版','更新后','更新版']\n",
    "    latest = {}\n",
    "    for it in anns:\n",
    "        sec   = it['secCode']\n",
    "        title = it['announcementTitle']\n",
    "        m     = re.search(r\"(\\d{4})年\", title)\n",
    "        yr    = m.group(1) if m else \"\"\n",
    "        key   = (sec, yr)\n",
    "        if key not in latest:\n",
    "            latest[key] = it\n",
    "        else:\n",
    "            prev = latest[key]['announcementTitle']\n",
    "            # 若本条为修订版，且已有条目不是，则替换\n",
    "            if any(kw in title for kw in rev_kws) and not any(kw in prev for kw in rev_kws):\n",
    "                latest[key] = it\n",
    "    return list(latest.values())\n",
    "\n",
    "\n",
    "def download_reports_for_year(year: int) -> list[dict]:\n",
    "    \"\"\"\n",
    "    抓取目标年度报告公告（只分次年段以捕获跨年发布）：\n",
    "    segments: year+1 的若干子区间\n",
    "    \"\"\"\n",
    "    ny = year + 1\n",
    "    segments = [\n",
    "        f\"{ny}-01-01~{ny}-04-01\", f\"{ny}-04-02~{ny}-04-15\",\n",
    "        f\"{ny}-04-16~{ny}-04-22\", f\"{ny}-04-23~{ny}-04-26\",\n",
    "        f\"{ny}-04-27~{ny}-04-28\", f\"{ny}-04-29~{ny}-04-30\",\n",
    "        f\"{ny}-05-01~{ny}-07-31\", f\"{ny}-08-01~{ny}-10-31\",\n",
    "        f\"{ny}-11-01~{ny}-11-30\", f\"{ny}-12-01~{ny}-12-31\"\n",
    "    ]\n",
    "    all_ann = []\n",
    "    for seg in segments:\n",
    "        all_ann.extend(download_report(seg))\n",
    "\n",
    "    # 排除无效关键词\n",
    "    filtered = [\n",
    "        x for x in all_ann\n",
    "        if not any(kw in x['announcementTitle'] for kw in exclude_keywords)\n",
    "    ]\n",
    "    return filter_latest_versions(filtered)\n",
    "\n",
    "\n",
    "def write_selected_excel(anns: list[dict], year: int) -> None:\n",
    "    \"\"\"\n",
    "    按映射表原始顺序，输出可转债→正股的年报链接\n",
    "    列：可转债代码、可转债名称、公司代码、公司简称、标题、年份、年报链接\n",
    "    \"\"\"\n",
    "    df_map = pd.read_excel(mapping_file, dtype=str)\n",
    "    df_map['sec_no_suf'] = df_map['正股代码'].str.split('.').str[0]\n",
    "\n",
    "    # 构建 secCode → 公告 的映射，后面快速查找\n",
    "    ann_dict = {it['secCode']: it for it in anns}\n",
    "\n",
    "    wb = openpyxl.Workbook()\n",
    "    ws = wb.active\n",
    "    ws.title = f\"{year}年报\"\n",
    "    ws.append([\n",
    "        \"可转债代码\", \"可转债名称\",\n",
    "        \"公司代码\", \"公司简称\",\n",
    "        \"标题\", \"年份\", \"年报链接\"\n",
    "    ])\n",
    "\n",
    "    count = 0\n",
    "    for _, row in df_map.iterrows():\n",
    "        bond_code = row['代码']\n",
    "        bond_name = row.get('名称', \"\")\n",
    "        sec       = row['sec_no_suf']\n",
    "        if sec not in ann_dict:\n",
    "            continue\n",
    "        it  = ann_dict[sec]\n",
    "        raw = re.sub(r\"<.*?>\", \"\", it['announcementTitle']).replace(\"：\", \"\")\n",
    "        title = f\"《{raw}》\"\n",
    "        m     = re.search(r\"(\\d{4})年\", raw)\n",
    "        yr    = m.group(1) if m else \"\"\n",
    "        url   = f\"http://static.cninfo.com.cn/{it['adjunctUrl']}\"\n",
    "\n",
    "        ws.append([bond_code, bond_name, sec, it['secName'], title, yr, url])\n",
    "        count += 1\n",
    "\n",
    "    dst = os.path.join(output_dir, f\"年报链接_{year}_选取公司{GZH}.xlsx\")\n",
    "    wb.save(dst)\n",
    "    print(f\"✅ 已保存：{dst} （共 {count} 条链接）\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 1) 深市 & 沪市 轮询抓取\n",
    "    all_ann = []\n",
    "    for market in (\"szse\", \"shse\"):\n",
    "        column = market\n",
    "        all_ann.extend(download_reports_for_year(YEAR))\n",
    "\n",
    "    # 2) 去重（跨市场可能重复）并保留最新版本\n",
    "    all_ann = filter_latest_versions(all_ann)\n",
    "\n",
    "    # 3) 按映射顺序输出最终文件\n",
    "    write_selected_excel(all_ann, YEAR)\n",
    "\n",
    "    print(f\"---- {YEAR} 年下载完成 ----\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 已输出：/Users/sam/Desktop/cninfo_output/年报链接_2024_选取公司【年报】.xlsx\n",
      "---- 2024 年下载完成 ----\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import requests\n",
    "import openpyxl\n",
    "import pandas as pd\n",
    "\n",
    "# —— 参数配置 —— \n",
    "YEAR             = 2024                           # 目标年份\n",
    "GZH              = \"【年报】\"\n",
    "exclude_keywords = ['英文', '已取消', '摘要']\n",
    "# 行业过滤，不需要则留空\n",
    "# plate 可在循环中切换\n",
    "# market (column) 可在循环中切换\n",
    "\n",
    "# 输出目录\n",
    "output_dir = os.path.expanduser(\"~/Desktop/cninfo_output\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# 正股映射表路径（第一部分脚本生成）\n",
    "mapping_file = os.path.expanduser(\"~/Desktop/正股映射结果.xlsx\")\n",
    "\n",
    "# 主流市场列（column）与板块（plate）列表\n",
    "MARKETS = [\"szse\", \"shse\"]\n",
    "PLATES  = [ \"sz\", \"sh\", \"szmb\", \"shmb\", \"szcy\", \"shkcp\", \"bj\"]\n",
    "\n",
    "\n",
    "def get_report(page_num: int, date_range: str, column: str, plate: str) -> requests.Response:\n",
    "    \"\"\"调用巨潮网历史公告查询接口\"\"\"\n",
    "    url = \"http://www.cninfo.com.cn/new/hisAnnouncement/query\"\n",
    "    headers = {\n",
    "        \"Accept\": \"*/*\",\n",
    "        \"Accept-Encoding\": \"gzip, deflate\",\n",
    "        \"Accept-Language\": \"zh-CN,zh;q=0.9\",\n",
    "        \"Content-Type\": \"application/x-www-form-urlencoded; charset=UTF-8\",\n",
    "        \"Origin\": \"http://www.cninfo.com.cn\",\n",
    "        \"Referer\": (\n",
    "            \"http://www.cninfo.com.cn/new/commonUrl/\"\n",
    "            \"pageOfSearch?url=disclosure/list/search\"\n",
    "            \"&checkedCategory=category_ndbg_szsh\"\n",
    "        ),\n",
    "        \"User-Agent\": \"Mozilla/5.0\",\n",
    "        \"X-Requested-With\": \"XMLHttpRequest\"\n",
    "    }\n",
    "    payload = {\n",
    "        \"pageNum\":   page_num,\n",
    "        \"pageSize\":  30,\n",
    "        \"column\":    column,\n",
    "        \"tabName\":   \"fulltext\",\n",
    "        \"plate\":     plate,\n",
    "        \"searchkey\": \"\",\n",
    "        \"secid\":     \"\",\n",
    "        \"category\":  \"category_ndbg_szsh\",\n",
    "        \"trade\":     \"\",\n",
    "        \"seDate\":    date_range,\n",
    "        \"sortName\":  \"code\",\n",
    "        \"sortType\":  \"asc\",\n",
    "        \"isHLtitle\": \"false\"\n",
    "    }\n",
    "    return requests.post(url, data=payload, headers=headers)\n",
    "\n",
    "\n",
    "def download_reports_for_segments(segments: list[str], column: str, plate: str) -> list[dict]:\n",
    "    \"\"\"\n",
    "    对于给定 market(column) 和 plate，按各时间段分页拉取公告\n",
    "    \"\"\"\n",
    "    all_ann = []\n",
    "    for date_range in segments:\n",
    "        # 首先请求第一页看总页数\n",
    "        try:\n",
    "            total = get_report(1, date_range, column, plate).json().get(\"totalpages\", 0)\n",
    "        except Exception:\n",
    "            continue\n",
    "        if total <= 0:\n",
    "            continue\n",
    "\n",
    "        page = 1\n",
    "        while page <= total:\n",
    "            for _ in range(3):  # 重试三次\n",
    "                resp = get_report(page, date_range, column, plate)\n",
    "                try:\n",
    "                    resp.raise_for_status()\n",
    "                    anns = resp.json().get(\"announcements\", [])\n",
    "                    if anns:\n",
    "                        all_ann.extend(anns)\n",
    "                    break\n",
    "                except Exception:\n",
    "                    time.sleep(2)\n",
    "            page += 1\n",
    "\n",
    "    # 排除摘要等无用记录\n",
    "    filtered = [\n",
    "        x for x in all_ann\n",
    "        if not any(kw in x['announcementTitle'] for kw in exclude_keywords)\n",
    "    ]\n",
    "    return filtered\n",
    "\n",
    "\n",
    "def filter_latest_versions(anns: list[dict]) -> list[dict]:\n",
    "    \"\"\"同一公司同一年只保留最新“更正/修订”版本\"\"\"\n",
    "    rev_kws = ['更正','更正后','更正版','修订后','修订版','更新后','更新版']\n",
    "    latest = {}\n",
    "    for it in anns:\n",
    "        sec   = it['secCode']\n",
    "        title = it['announcementTitle']\n",
    "        m     = re.search(r\"(\\d{4})年\", title)\n",
    "        yr    = m.group(1) if m else \"\"\n",
    "        key   = (sec, yr)\n",
    "        if key not in latest:\n",
    "            latest[key] = it\n",
    "        else:\n",
    "            prev = latest[key]['announcementTitle']\n",
    "            # 若本条为修订版，且已有条目不是，则替换\n",
    "            if any(kw in title for kw in rev_kws) and not any(kw in prev for kw in rev_kws):\n",
    "                latest[key] = it\n",
    "    return list(latest.values())\n",
    "\n",
    "\n",
    "def collect_all_announcements(year: int) -> list[dict]:\n",
    "    \"\"\"\n",
    "    在所有 market×plate 下抓取次年各子区间公告（捕获跨年发布）\n",
    "    \"\"\"\n",
    "    ny = year + 1\n",
    "    segments = [\n",
    "        f\"{ny}-01-01~{ny}-04-01\", f\"{ny}-04-02~{ny}-04-15\",\n",
    "        f\"{ny}-04-16~{ny}-04-22\", f\"{ny}-04-23~{ny}-04-26\",\n",
    "        f\"{ny}-04-27~{ny}-04-28\", f\"{ny}-04-29~{ny}-04-30\",\n",
    "        f\"{ny}-05-01~{ny}-07-31\", f\"{ny}-08-01~{ny}-10-31\",\n",
    "        f\"{ny}-11-01~{ny}-11-30\", f\"{ny}-12-01~{ny}-12-31\"\n",
    "    ]\n",
    "    raw = []\n",
    "    for col in MARKETS:\n",
    "        for pl in PLATES:\n",
    "            raw.extend(download_reports_for_segments(segments, col, pl))\n",
    "    # 去重（不同 market/plate 可能重复），仅保留最新版本\n",
    "    return filter_latest_versions(raw)\n",
    "\n",
    "\n",
    "def write_selected_excel(anns: list[dict], year: int) -> None:\n",
    "    \"\"\"\n",
    "    按映射表顺序输出最终列表，若未找到公告，则链接等留空\n",
    "    \"\"\"\n",
    "    # 1) 读映射表并保持顺序\n",
    "    df_map = pd.read_excel(mapping_file, dtype=str)\n",
    "    df_map['sec_no_suf'] = df_map['正股代码'].str.split('.').str[0]\n",
    "\n",
    "    # 2) 构建 secCode→公告 的快速查找字典\n",
    "    ann_dict = {(it['secCode'], re.search(r\"(\\d{4})年\", it['announcementTitle']).group(1) if re.search(r\"(\\d{4})年\", it['announcementTitle']) else \"\"): it\n",
    "                for it in anns}\n",
    "\n",
    "    # 3) 创建 Excel\n",
    "    wb = openpyxl.Workbook()\n",
    "    ws = wb.active\n",
    "    ws.title = f\"{year}年报\"\n",
    "    ws.append([\n",
    "        \"可转债代码\",\"可转债名称\",\n",
    "        \"公司代码\",\"公司简称\",\n",
    "        \"标题\",\"年份\",\"年报链接\"\n",
    "    ])\n",
    "\n",
    "    # 4) 按原始映射顺序回填\n",
    "    for _, row in df_map.iterrows():\n",
    "        bond_code = row['代码']\n",
    "        bond_name = row.get('名称', \"\")\n",
    "        sec       = row['sec_no_suf']\n",
    "        comp_name = row['正股名称']\n",
    "\n",
    "        # 查公告：尝试匹配 (sec, YEAR)\n",
    "        key = (sec, str(year))\n",
    "        it  = ann_dict.get(key)\n",
    "\n",
    "        if it:\n",
    "            raw = re.sub(r\"<.*?>\",\"\", it['announcementTitle']).replace(\"：\",\"\")\n",
    "            title = f\"《{raw}》\"\n",
    "            url   = f\"http://static.cninfo.com.cn/{it['adjunctUrl']}\"\n",
    "            yr    = str(year)\n",
    "        else:\n",
    "            title = \"\"\n",
    "            url   = \"\"\n",
    "            yr    = \"\"\n",
    "\n",
    "        ws.append([bond_code, bond_name, sec, comp_name, title, yr, url])\n",
    "\n",
    "    dst = os.path.join(output_dir, f\"年报链接_{year}_选取公司{GZH}.xlsx\")\n",
    "    wb.save(dst)\n",
    "    print(f\"✅ 已输出：{dst}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 1) 抓公告并过滤\n",
    "    all_ann = collect_all_announcements(YEAR)\n",
    "    # 2) 按映射顺序输出最终 Excel\n",
    "    write_selected_excel(all_ann, YEAR)\n",
    "    print(f\"---- {YEAR} 年下载完成 ----\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 已输出：/Users/sam/Desktop/cninfo_output/年报链接_2024_选取公司【年报】.xlsx\n",
      "---- 2024 年下载完成 ----\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import requests\n",
    "import openpyxl\n",
    "import pandas as pd\n",
    "\n",
    "# —— 参数配置 —— \n",
    "YEAR             = 2024                           # 目标年份\n",
    "GZH              = \"【年报】\"\n",
    "# 排除列表：可加入 '更正后','修订版' 等，避免重复或旧版本年报\n",
    "exclude_keywords = ['英文', '已取消', '摘要']\n",
    "\n",
    "# 输出目录\n",
    "output_dir = os.path.expanduser(\"~/Desktop/cninfo_output\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# 正股映射表路径（第一部分脚本生成）\n",
    "mapping_file = os.path.expanduser(\"~/Desktop/正股映射结果.xlsx\")\n",
    "\n",
    "# —— 市场控制 (column) —— \n",
    "# szse = 深圳交易所（含深主板、中小板、创业板）\n",
    "# shse = 上海交易所（含主板）\n",
    "MARKETS = [\"szse\", \"shse\"]\n",
    "\n",
    "# —— 板块控制 (plate) —— \n",
    "# \"\"      = 默认，不做二次过滤，拉取 category_ndbg_szsh 下所有子板块\n",
    "# sz      = 深市（等同 column=\"szse\" + plate=\"\"）\n",
    "# szmb    = 深市主板\n",
    "# szcy    = 创业板\n",
    "# sh      = 沪市（等同 column=\"shse\" + plate=\"\"）\n",
    "# shmb    = 沪市主板\n",
    "# shkcp   = 科创板（需配合 category_ndbg_shkcp 使用）\n",
    "# bj      = 北交所（需配合 category_ndbg_bj 使用）\n",
    "PLATES  = [\"\", \"sz\", \"szmb\", \"szcy\", \"sh\", \"shmb\", \"shkcp\", \"bj\"]\n",
    "\n",
    "\n",
    "def get_report(page_num: int, date_range: str, column: str, plate: str) -> requests.Response:\n",
    "    \"\"\"调用巨潮网历史公告查询接口\"\"\"\n",
    "    url = \"http://www.cninfo.com.cn/new/hisAnnouncement/query\"\n",
    "    payload = {\n",
    "        \"pageNum\":   page_num,\n",
    "        \"pageSize\":  30,\n",
    "        \"column\":    column,       # 来自 MARKETS\n",
    "        \"tabName\":   \"fulltext\",\n",
    "        \"category\":  \"category_ndbg_szsh\",  # 年报大类（深市主板/中小/创业板）\n",
    "        \"plate\":     plate,        # 子板块，参见 PLATES 注释\n",
    "        \"searchkey\": \"\",\n",
    "        \"secid\":     \"\",\n",
    "        \"trade\":     \"\",\n",
    "        \"seDate\":    date_range,\n",
    "        \"sortName\":  \"code\",\n",
    "        \"sortType\":  \"asc\",\n",
    "        \"isHLtitle\": \"false\"\n",
    "    }\n",
    "    headers = {\n",
    "        \"Accept\":             \"*/*\",\n",
    "        \"Accept-Encoding\":    \"gzip, deflate\",\n",
    "        \"Accept-Language\":    \"zh-CN,zh;q=0.9\",\n",
    "        \"Content-Type\":       \"application/x-www-form-urlencoded; charset=UTF-8\",\n",
    "        \"Origin\":             \"http://www.cninfo.com.cn\",\n",
    "        \"Referer\": (\n",
    "            \"http://www.cninfo.com.cn/new/commonUrl/\"\n",
    "            \"pageOfSearch?url=disclosure/list/search\"\n",
    "            \"&checkedCategory=category_ndbg_szsh\"\n",
    "        ),\n",
    "        \"User-Agent\":         \"Mozilla/5.0\",\n",
    "        \"X-Requested-With\":   \"XMLHttpRequest\"\n",
    "    }\n",
    "    return requests.post(url, data=payload, headers=headers)\n",
    "\n",
    "\n",
    "def download_reports_for_segments(segments: list[str], column: str, plate: str) -> list[dict]:\n",
    "    \"\"\"\n",
    "    对于给定 market(column) 和 plate，按各时间段分页拉取公告\n",
    "    \"\"\"\n",
    "    all_ann = []\n",
    "    for date_range in segments:\n",
    "        try:\n",
    "            total = get_report(1, date_range, column, plate).json().get(\"totalpages\", 0)\n",
    "        except Exception:\n",
    "            continue\n",
    "        if total <= 0:\n",
    "            continue\n",
    "\n",
    "        page = 1\n",
    "        while page <= total:\n",
    "            for _ in range(3):  # 重试三次\n",
    "                resp = get_report(page, date_range, column, plate)\n",
    "                try:\n",
    "                    resp.raise_for_status()\n",
    "                    anns = resp.json().get(\"announcements\", [])\n",
    "                    if anns:\n",
    "                        all_ann.extend(anns)\n",
    "                    break\n",
    "                except Exception:\n",
    "                    time.sleep(2)\n",
    "            page += 1\n",
    "\n",
    "    # 排除摘要等无用记录\n",
    "    return [\n",
    "        x for x in all_ann\n",
    "        if not any(kw in x['announcementTitle'] for kw in exclude_keywords)\n",
    "    ]\n",
    "\n",
    "\n",
    "def filter_latest_versions(anns: list[dict]) -> list[dict]:\n",
    "    \"\"\"同一公司同一年只保留最新“更正/修订”版本\"\"\"\n",
    "    rev_kws = ['更正','更正后','更正版','修订后','修订版','更新后','更新版']\n",
    "    latest = {}\n",
    "    for it in anns:\n",
    "        sec   = it['secCode']\n",
    "        title = it['announcementTitle']\n",
    "        m     = re.search(r\"(\\d{4})年\", title)\n",
    "        yr    = m.group(1) if m else \"\"\n",
    "        key   = (sec, yr)\n",
    "        if key not in latest:\n",
    "            latest[key] = it\n",
    "        else:\n",
    "            prev = latest[key]['announcementTitle']\n",
    "            if any(kw in title for kw in rev_kws) and not any(kw in prev for kw in rev_kws):\n",
    "                latest[key] = it\n",
    "    return list(latest.values())\n",
    "\n",
    "\n",
    "def collect_all_announcements(year: int) -> list[dict]:\n",
    "    \"\"\"\n",
    "    在所有 market×plate 下抓取次年各子区间公告（捕获跨年发布）\n",
    "    \"\"\"\n",
    "    ny = year + 1\n",
    "    segments = [\n",
    "        f\"{ny}-01-01~{ny}-04-01\", f\"{ny}-04-02~{ny}-04-15\",\n",
    "        f\"{ny}-04-16~{ny}-04-22\", f\"{ny}-04-23~{ny}-04-26\",\n",
    "        f\"{ny}-04-27~{ny}-04-28\", f\"{ny}-04-29~{ny}-04-30\",\n",
    "        f\"{ny}-05-01~{ny}-07-31\", f\"{ny}-08-01~{ny}-10-31\",\n",
    "        f\"{ny}-11-01~{ny}-11-30\", f\"{ny}-12-01~{ny}-12-31\"\n",
    "    ]\n",
    "    raw = []\n",
    "    for col in MARKETS:\n",
    "        for pl in PLATES:\n",
    "            raw.extend(download_reports_for_segments(segments, col, pl))\n",
    "    return filter_latest_versions(raw)\n",
    "\n",
    "\n",
    "def write_selected_excel(anns: list[dict], year: int) -> None:\n",
    "    \"\"\"\n",
    "    按映射表顺序输出最终列表，若未找到公告，则链接等留空\n",
    "    \"\"\"\n",
    "    df_map = pd.read_excel(mapping_file, dtype=str)\n",
    "    df_map['sec_no_suf'] = df_map['正股代码'].str.split('.').str[0]\n",
    "\n",
    "    ann_dict = {\n",
    "        (it['secCode'],\n",
    "         re.search(r\"(\\d{4})年\", it['announcementTitle']).group(1) if re.search(r\"(\\d{4})年\", it['announcementTitle']) else \"\")\n",
    "        : it\n",
    "        for it in anns\n",
    "    }\n",
    "\n",
    "    wb = openpyxl.Workbook()\n",
    "    ws = wb.active\n",
    "    ws.title = f\"{year}年报\"\n",
    "    ws.append([\n",
    "        \"可转债代码\",\"可转债名称\",\n",
    "        \"公司代码\",\"公司简称\",\n",
    "        \"标题\",\"年份\",\"年报链接\"\n",
    "    ])\n",
    "\n",
    "    for _, row in df_map.iterrows():\n",
    "        bond_code = row['代码']\n",
    "        bond_name = row.get('名称', \"\")\n",
    "        sec       = row['sec_no_suf']\n",
    "        comp_name = row['正股名称']\n",
    "\n",
    "        key = (sec, str(year))\n",
    "        it  = ann_dict.get(key)\n",
    "        if it:\n",
    "            raw   = re.sub(r\"<.*?>\",\"\", it['announcementTitle']).replace(\"：\",\"\")\n",
    "            title = f\"《{raw}》\"\n",
    "            url   = f\"http://static.cninfo.com.cn/{it['adjunctUrl']}\"\n",
    "            yr    = str(year)\n",
    "        else:\n",
    "            title = \"\"\n",
    "            url   = \"\"\n",
    "            yr    = \"\"\n",
    "\n",
    "        ws.append([bond_code, bond_name, sec, comp_name, title, yr, url])\n",
    "\n",
    "    dst = os.path.join(output_dir, f\"年报链接_{year}_选取公司{GZH}.xlsx\")\n",
    "    wb.save(dst)\n",
    "    print(f\"✅ 已输出：{dst}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 1) 抓公告并过滤\n",
    "    all_ann = collect_all_announcements(YEAR)\n",
    "    # 2) 按映射顺序输出最终 Excel\n",
    "    write_selected_excel(all_ann, YEAR)\n",
    "    print(f\"---- {YEAR} 年下载完成 ----\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 已输出：/Users/sam/Desktop/cninfo_output/年报链接_2024_选取公司【年报】.xlsx\n",
      "---- 2024 年年报链接抓取完成 ----\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "按指定正股列表（公司代码或公司简称）精准抓取 2024 年度报告公告并输出链接\n",
    "使用 searchkey 参数直接索引，不再依赖 secid\n",
    "\"\"\"\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import requests\n",
    "import openpyxl\n",
    "import pandas as pd\n",
    "\n",
    "# —— 参数配置 ——\n",
    "YEAR             = 2024                          # 目标年份\n",
    "GZH              = \"【年报】\"\n",
    "exclude_keywords = ['英文', '已取消', '摘要']       # 排除关键字\n",
    "\n",
    "# 输入/输出路径\n",
    "mapping_file = os.path.expanduser(\"~/Desktop/正股映射结果.xlsx\")\n",
    "output_dir   = os.path.expanduser(\"~/Desktop/cninfo_output\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# 可选过滤：使用公司代码或简称过滤\n",
    "sec_filter  = []  # 例 ['600519','000001']\n",
    "name_filter = []  # 例 ['贵州茅台','平安银行']\n",
    "\n",
    "# search_by: 'code' 或 'name'\n",
    "search_by = 'name'\n",
    "\n",
    "# 时间分段：全年 + 跨年\n",
    "segments = [\n",
    "    f\"{YEAR}-01-01~{YEAR}-12-31\",\n",
    "    f\"{YEAR+1}-01-01~{YEAR+1}-04-30\"\n",
    "]\n",
    "\n",
    "# 调用接口：通过 searchkey 精准搜索\n",
    "def get_report(page_num: int, date_range: str, searchkey: str) -> requests.Response:\n",
    "    url = \"http://www.cninfo.com.cn/new/hisAnnouncement/query\"\n",
    "    payload = {\n",
    "        \"pageNum\":  page_num,\n",
    "        \"pageSize\": 30,\n",
    "        \"column\":   \"\",             # 默认空，不做市场过滤\n",
    "        \"plate\":    \"\",             # 默认空，不做板块过滤\n",
    "        \"tabName\":  \"fulltext\",\n",
    "        \"category\": \"category_ndbg_szsh\",\n",
    "        \"searchkey\": searchkey,\n",
    "        \"seDate\":   date_range,\n",
    "        \"sortName\": \"code\",\n",
    "        \"sortType\": \"asc\",\n",
    "        \"isHLtitle\": \"false\"\n",
    "    }\n",
    "    headers = {\n",
    "        \"Accept\":             \"*/*\",\n",
    "        \"Content-Type\":       \"application/x-www-form-urlencoded; charset=UTF-8\",\n",
    "        \"Origin\":             \"http://www.cninfo.com.cn\",\n",
    "        \"Referer\":            \"http://www.cninfo.com.cn/new/commonUrl/pageOfSearch?url=disclosure/list/search\",\n",
    "        \"User-Agent\":         \"Mozilla/5.0\",\n",
    "        \"X-Requested-With\":   \"XMLHttpRequest\"\n",
    "    }\n",
    "    return requests.post(url, data=payload, headers=headers)\n",
    "\n",
    "# 批量抓取：使用公司列表 + searchkey\n",
    "def collect_announcements(codes_names: list[tuple]) -> list[dict]:\n",
    "    all_ann = []\n",
    "    for sec, comp in codes_names:\n",
    "        # 过滤\n",
    "        if sec_filter and sec not in sec_filter:\n",
    "            continue\n",
    "        if name_filter and comp not in name_filter:\n",
    "            continue\n",
    "        # 选择 searchkey\n",
    "        key = sec if search_by=='code' else comp\n",
    "        for dr in segments:\n",
    "            try:\n",
    "                resp  = get_report(1, dr, key)\n",
    "                total = resp.json().get(\"totalpages\", 0)\n",
    "            except Exception:\n",
    "                continue\n",
    "            if total <= 0:\n",
    "                continue\n",
    "            page = 1\n",
    "            while page <= total:\n",
    "                for _ in range(3):\n",
    "                    r = get_report(page, dr, key)\n",
    "                    try:\n",
    "                        r.raise_for_status()\n",
    "                        anns = r.json().get(\"announcements\", [])\n",
    "                        if anns:\n",
    "                            all_ann.extend(anns)\n",
    "                        break\n",
    "                    except Exception:\n",
    "                        time.sleep(2)\n",
    "                page += 1\n",
    "    # 排除无用记录\n",
    "    return [a for a in all_ann if not any(kw in a.get('announcementTitle','') for kw in exclude_keywords)]\n",
    "\n",
    "# 保留最新版本\n",
    "def filter_latest_versions(anns: list) -> list[dict]:\n",
    "    rev_kws = ['更正','更正后','更正版','修订后','修订版','更新后','更新版']\n",
    "    latest = {}\n",
    "    for it in anns:\n",
    "        sec   = it.get('secCode','')\n",
    "        title = it.get('announcementTitle','')\n",
    "        m     = re.search(r\"(\\d{4})年\", title)\n",
    "        yr    = m.group(1) if m else \"\"\n",
    "        key   = (sec, yr)\n",
    "        if key not in latest or (\n",
    "            any(kw in title for kw in rev_kws)\n",
    "            and not any(kw in latest[key].get('announcementTitle','') for kw in rev_kws)\n",
    "        ):\n",
    "            latest[key] = it\n",
    "    return list(latest.values())\n",
    "\n",
    "# 输出为 Excel\n",
    "def write_selected_excel(anns: list, year: int) -> None:\n",
    "    df_map = pd.read_excel(mapping_file, dtype=str).fillna('')\n",
    "    df_map['sec_no_suf'] = df_map['正股代码'].str.split('.').str[0]\n",
    "    # 过滤\n",
    "    if name_filter:\n",
    "        df_map = df_map[df_map['正股名称'].isin(name_filter)]\n",
    "    if sec_filter:\n",
    "        df_map = df_map[df_map['sec_no_suf'].isin(sec_filter)]\n",
    "    ann_dict = {\n",
    "        (it.get('secCode',''), re.search(r\"(\\d{4})年\", it.get('announcementTitle','')).group(1) if re.search(r\"(\\d{4})年\", it.get('announcementTitle','')) else \"\"): it\n",
    "        for it in anns\n",
    "    }\n",
    "    wb = openpyxl.Workbook()\n",
    "    ws = wb.active; ws.title = f\"{year}年报\"\n",
    "    ws.append([\"可转债代码\",\"可转债名称\",\"公司代码\",\"公司简称\",\"标题\",\"年份\",\"年报链接\"])\n",
    "    for _, row in df_map.iterrows():\n",
    "        bond_code = row.get('代码',''); bond_name = row.get('名称','')\n",
    "        sec       = row.get('sec_no_suf',''); comp_name = row.get('正股名称','')\n",
    "        key       = (sec, str(year)); it = ann_dict.get(key, {})\n",
    "        if it:\n",
    "            raw   = re.sub(r\"<.*?>\",\"\", it.get('announcementTitle','')).replace(\"：\",\"\")\n",
    "            title = f\"《{raw}》\"\n",
    "            url   = f\"http://static.cninfo.com.cn/{it.get('adjunctUrl','')}\"\n",
    "            yr    = str(year)\n",
    "        else:\n",
    "            title = url = yr = \"\"\n",
    "        ws.append([bond_code, bond_name, sec, comp_name, title, yr, url])\n",
    "    dst = os.path.join(output_dir, f\"年报链接_{year}_选取公司{GZH}.xlsx\")\n",
    "    wb.save(dst); print(f\"✅ 已输出：{dst}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    df_map = pd.read_excel(mapping_file, dtype=str).fillna('')\n",
    "    codes_names = list(zip(\n",
    "        df_map['正股代码'].str.split('.').str[0],\n",
    "        df_map['正股名称']\n",
    "    ))\n",
    "    raw_ann = collect_announcements(codes_names)\n",
    "    all_ann = filter_latest_versions(raw_ann)\n",
    "    write_selected_excel(all_ann, YEAR)\n",
    "    print(f\"---- {YEAR} 年年报链接抓取完成 ----\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 已输出：/Users/sam/Desktop/cninfo_output/年报链接_2024_选取公司【年报】.xlsx\n",
      "---- 2024 年年报链接抓取完成 ----\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "按指定正股列表（公司代码或简称）精准抓取 2024 年度报告公告并输出链接\n",
    "使用 searchkey 参数直接索引，不再遍历市场/板块\n",
    "\"\"\"\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import requests\n",
    "import openpyxl\n",
    "import pandas as pd\n",
    "\n",
    "# —— 参数配置 ——\n",
    "YEAR             = 2024                          # 目标年份\n",
    "GZH              = \"【年报】\"\n",
    "exclude_keywords = ['英文', '已取消', '摘要']       # 排除关键字\n",
    "\n",
    "# 输入/输出路径\n",
    "mapping_file = os.path.expanduser(\"~/Desktop/正股映射结果.xlsx\")\n",
    "output_dir   = os.path.expanduser(\"~/Desktop/cninfo_output\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# 可选过滤：sec_filter 按代码过滤，name_filter 按简称过滤\n",
    "sec_filter  = []  # 例 ['600519','000001']\n",
    "name_filter = []  # 例 ['贵州茅台','平安银行']\n",
    "\n",
    "# search_by: 'code' 或 'name'\n",
    "search_by = 'code'\n",
    "\n",
    "# 时间分段：全年 + 跨年\n",
    "segments = [\n",
    "    f\"{YEAR}-01-01~{YEAR}-12-31\",\n",
    "    f\"{YEAR+1}-01-01~{YEAR+1}-04-30\"\n",
    "]\n",
    "\n",
    "# 调用接口：通过 searchkey 精准搜索，不使用 market/plate\n",
    "def get_report(page_num: int, date_range: str, searchkey: str) -> requests.Response:\n",
    "    url = \"http://www.cninfo.com.cn/new/hisAnnouncement/query\"\n",
    "    payload = {\n",
    "        \"pageNum\":   page_num,\n",
    "        \"pageSize\":  30,\n",
    "        \"column\":    \"\",             # 空：不做市场过滤\n",
    "        \"plate\":     \"\",             # 空：不做板块过滤\n",
    "        \"tabName\":   \"fulltext\",\n",
    "        \"category\":  \"category_ndbg_szsh\",\n",
    "        \"searchkey\": searchkey,\n",
    "        \"seDate\":    date_range,\n",
    "        \"sortName\":  \"code\",\n",
    "        \"sortType\":  \"asc\",\n",
    "        \"isHLtitle\": \"false\"\n",
    "    }\n",
    "    headers = {\n",
    "        \"Accept\":             \"*/*\",\n",
    "        \"Content-Type\":       \"application/x-www-form-urlencoded; charset=UTF-8\",\n",
    "        \"Origin\":             \"http://www.cninfo.com.cn\",\n",
    "        \"Referer\":            \"http://www.cninfo.com.cn/new/commonUrl/pageOfSearch?url=disclosure/list/search\",\n",
    "        \"User-Agent\":         \"Mozilla/5.0\",\n",
    "        \"X-Requested-With\":   \"XMLHttpRequest\"\n",
    "    }\n",
    "    return requests.post(url, data=payload, headers=headers)\n",
    "\n",
    "# 批量抓取：根据公司列表和 searchkey\n",
    "def collect_announcements(codes_names: list) -> list[dict]:\n",
    "    all_ann = []\n",
    "    for sec, comp in codes_names:\n",
    "        sec = str(sec).strip()\n",
    "        if not sec.isdigit():\n",
    "            continue\n",
    "        if sec_filter and sec not in sec_filter:\n",
    "            continue\n",
    "        if name_filter and comp not in name_filter:\n",
    "            continue\n",
    "        # 确定 searchkey\n",
    "        key = sec if search_by=='code' else comp\n",
    "        for dr in segments:\n",
    "            try:\n",
    "                resp  = get_report(1, dr, key)\n",
    "                total = resp.json().get(\"totalpages\", 0)\n",
    "            except Exception:\n",
    "                continue\n",
    "            if total <= 0:\n",
    "                continue\n",
    "            page = 1\n",
    "            while page <= total:\n",
    "                for _ in range(3):\n",
    "                    r = get_report(page, dr, key)\n",
    "                    try:\n",
    "                        r.raise_for_status()\n",
    "                        anns = r.json().get(\"announcements\", [])\n",
    "                        if anns:\n",
    "                            all_ann.extend(anns)\n",
    "                        break\n",
    "                    except Exception:\n",
    "                        time.sleep(2)\n",
    "                page += 1\n",
    "    # 排除无用记录\n",
    "    return [a for a in all_ann if not any(kw in a.get('announcementTitle','') for kw in exclude_keywords)]\n",
    "\n",
    "# 保留每家公司当年最新版本\n",
    "def filter_latest_versions(anns: list) -> list[dict]:\n",
    "    rev_kws = ['更正','更正后','更正版','修订后','修订版','更新后','更新版']\n",
    "    latest = {}\n",
    "    for it in anns:\n",
    "        sec   = it.get('secCode','')\n",
    "        title = it.get('announcementTitle','')\n",
    "        m     = re.search(r\"(\\d{4})年\", title)\n",
    "        yr    = m.group(1) if m else \"\"\n",
    "        key   = (sec, yr)\n",
    "        if key not in latest or (\n",
    "            any(kw in title for kw in rev_kws)\n",
    "            and not any(kw in latest[key].get('announcementTitle','') for kw in rev_kws)\n",
    "        ):\n",
    "            latest[key] = it\n",
    "    return list(latest.values())\n",
    "\n",
    "# 输出至 Excel\n",
    "def write_selected_excel(anns: list, year: int) -> None:\n",
    "    df_map = pd.read_excel(mapping_file, dtype=str).fillna('')\n",
    "    df_map['sec_no_suf'] = df_map['正股代码'].str.split('.').str[0]\n",
    "    if name_filter:\n",
    "        df_map = df_map[df_map['正股名称'].isin(name_filter)]\n",
    "    if sec_filter:\n",
    "        df_map = df_map[df_map['sec_no_suf'].isin(sec_filter)]\n",
    "    ann_dict = {\n",
    "        (it.get('secCode',''), re.search(r\"(\\d{4})年\", it.get('announcementTitle','')).group(1) if re.search(r\"(\\d{4})年\", it.get('announcementTitle','')) else \"\"): it\n",
    "        for it in anns\n",
    "    }\n",
    "    wb = openpyxl.Workbook(); ws = wb.active; ws.title = f\"{year}年报\"\n",
    "    ws.append([\"可转债代码\",\"可转债名称\",\"公司代码\",\"公司简称\",\"标题\",\"年份\",\"年报链接\"])\n",
    "    for _, row in df_map.iterrows():\n",
    "        bond_code = row.get('代码',''); bond_name = row.get('名称','')\n",
    "        sec       = row.get('sec_no_suf',''); comp_name = row.get('正股名称','')\n",
    "        key       = (sec, str(year)); it = ann_dict.get(key, {})\n",
    "        if it:\n",
    "            raw   = re.sub(r\"<.*?>\",\"\", it.get('announcementTitle','')).replace(\"：\",\"\")\n",
    "            title = f\"《{raw}》\"\n",
    "            url   = f\"http://static.cninfo.com.cn/{it.get('adjunctUrl','')}\"\n",
    "            yr    = str(year)\n",
    "        else:\n",
    "            title = url = yr = \"\"\n",
    "        ws.append([bond_code, bond_name, sec, comp_name, title, yr, url])\n",
    "    dst = os.path.join(output_dir, f\"年报链接_{year}_选取公司{GZH}.xlsx\")\n",
    "    wb.save(dst); print(f\"✅ 已输出：{dst}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    df_map = pd.read_excel(mapping_file, dtype=str).fillna('')\n",
    "    codes_names = list(zip(df_map['正股代码'].str.split('.').str[0], df_map['正股名称']))\n",
    "    raw_ann = collect_announcements(codes_names)\n",
    "    all_ann = filter_latest_versions(raw_ann)\n",
    "    write_selected_excel(all_ann, YEAR)\n",
    "    print(f\"---- {YEAR} 年年报链接抓取完成 ----\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 205\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✅ 已输出：\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdst\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 205\u001b[0m     all_ann \u001b[38;5;241m=\u001b[39m \u001b[43mcollect_all_announcements\u001b[49m\u001b[43m(\u001b[49m\u001b[43mYEAR\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m     write_selected_excel(all_ann, YEAR)\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m---- \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mYEAR\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m 年下载完成 ----\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[7], line 165\u001b[0m, in \u001b[0;36mcollect_all_announcements\u001b[0;34m(year)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m MARKETS:\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m pl \u001b[38;5;129;01min\u001b[39;00m PLATES:\n\u001b[0;32m--> 165\u001b[0m         raw\u001b[38;5;241m.\u001b[39mextend(\u001b[43mdownload_reports_for_segments\u001b[49m\u001b[43m(\u001b[49m\u001b[43msegments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpl\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m filter_latest_versions(raw)\n",
      "Cell \u001b[0;32mIn[7], line 113\u001b[0m, in \u001b[0;36mdownload_reports_for_segments\u001b[0;34m(segments, column, plate)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m3\u001b[39m):  \u001b[38;5;66;03m# 重试三次\u001b[39;00m\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 113\u001b[0m         resp \u001b[38;5;241m=\u001b[39m \u001b[43mget_report\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdate_range\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m         resp\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[1;32m    115\u001b[0m         anns \u001b[38;5;241m=\u001b[39m resp\u001b[38;5;241m.\u001b[39mjson()\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mannouncements\u001b[39m\u001b[38;5;124m\"\u001b[39m, [])\n",
      "Cell \u001b[0;32mIn[7], line 95\u001b[0m, in \u001b[0;36mget_report\u001b[0;34m(page_num, date_range, column, plate)\u001b[0m\n\u001b[1;32m     71\u001b[0m payload \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpageNum\u001b[39m\u001b[38;5;124m\"\u001b[39m:   page_num,\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpageSize\u001b[39m\u001b[38;5;124m\"\u001b[39m:  \u001b[38;5;241m30\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124misHLtitle\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfalse\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     85\u001b[0m }\n\u001b[1;32m     86\u001b[0m headers \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccept\u001b[39m\u001b[38;5;124m\"\u001b[39m:           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*/*\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccept-Language\u001b[39m\u001b[38;5;124m\"\u001b[39m:  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzh-CN,zh;q=0.9\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX-Requested-With\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mXMLHttpRequest\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     94\u001b[0m }\n\u001b[0;32m---> 95\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpayload\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/requests/api.py:115\u001b[0m, in \u001b[0;36mpost\u001b[0;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(url, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, json\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    104\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a POST request.\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \n\u001b[1;32m    106\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/requests/adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    664\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    682\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/urllib3/connectionpool.py:716\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    713\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_proxy(conn)\n\u001b[1;32m    715\u001b[0m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 716\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    717\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    718\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    719\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    720\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    723\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    724\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    726\u001b[0m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    727\u001b[0m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    729\u001b[0m \u001b[38;5;66;03m# mess.\u001b[39;00m\n\u001b[1;32m    730\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/urllib3/connectionpool.py:468\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    463\u001b[0m             httplib_response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[1;32m    464\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    465\u001b[0m             \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    466\u001b[0m             \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    467\u001b[0m             \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[0;32m--> 468\u001b[0m             \u001b[43msix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    469\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    470\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/urllib3/connectionpool.py:463\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    461\u001b[0m     \u001b[38;5;66;03m# Python 3\u001b[39;00m\n\u001b[1;32m    462\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 463\u001b[0m         httplib_response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    464\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    465\u001b[0m         \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    466\u001b[0m         \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    467\u001b[0m         \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m    468\u001b[0m         six\u001b[38;5;241m.\u001b[39mraise_from(e, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py:1349\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1347\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1348\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1349\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1350\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1351\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py:316\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 316\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    318\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py:277\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 277\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/socket.py:704\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    703\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 704\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    706\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import requests\n",
    "import openpyxl\n",
    "import pandas as pd\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "# —— 参数配置 ——\n",
    "YEAR = 2024\n",
    "GZH  = \"【年报】\"\n",
    "\n",
    "# 输出目录 & 映射表\n",
    "output_dir   = os.path.expanduser(\"~/Desktop/cninfo_output\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "mapping_file = os.path.expanduser(\"~/Desktop/正股映射结果.xlsx\")\n",
    "\n",
    "# —— 市场/板块控制（按你原来的保留） ——\n",
    "MARKETS = [\"szse\", \"shse\"]\n",
    "PLATES  = [\"\", \"sz\", \"szmb\", \"szcy\", \"sh\", \"shmb\", \"shkcp\", \"bj\"]\n",
    "\n",
    "# —— 标题过滤：只要中文完整版年报；剔除英文/摘要/取消等 ——\n",
    "EXCLUDE_KWS = [\n",
    "    '英文', '英文版', 'Annual', 'annual', 'Summary',\n",
    "    '摘要', '摘要版', '年报摘要', '年度报告摘要',\n",
    "    '取消', '已取消', '披露日期变更', '变更的公告', '提示性公告',\n",
    "    'H股公告', 'B股', '年报报告'\n",
    "]\n",
    "INCLUDE_AR_PAT = re.compile(r\"(年\\s*度\\s*报\\s*告|年\\s*报)\")\n",
    "\n",
    "# 空白归一（含不间断空格/全角空格）\n",
    "SPACE_RE = re.compile(r\"[\\s\\u00A0\\u3000]+\")\n",
    "def norm(s: str) -> str:\n",
    "    return SPACE_RE.sub(\"\", str(s or \"\").strip())\n",
    "\n",
    "# 年份识别：允许“2024 年/年度/年报”等写法与空格\n",
    "YEAR_PATS = [\n",
    "    re.compile(r\"(20\\d{2})\\s*年?\\s*度?\\s*报\\s*告\"),\n",
    "    re.compile(r\"(20\\d{2})\\s*年?\\s*报(?!告)\"),\n",
    "]\n",
    "def extract_year(title: str) -> str:\n",
    "    t = norm(title)\n",
    "    for pat in YEAR_PATS:\n",
    "        m = pat.search(t)\n",
    "        if m:\n",
    "            return m.group(1)\n",
    "    return \"\"\n",
    "\n",
    "def is_valid_cn_annual_2024(title: str) -> bool:\n",
    "    t = norm(title)\n",
    "    if not INCLUDE_AR_PAT.search(t):\n",
    "        return False\n",
    "    if any(kw in t for kw in EXCLUDE_KWS):\n",
    "        return False\n",
    "    return extract_year(t) == str(YEAR)\n",
    "\n",
    "# 不同板块对应的 category\n",
    "def category_for_plate(plate: str) -> str:\n",
    "    if plate == \"shkcp\":\n",
    "        return \"category_ndbg_shkcp\"   # 科创板\n",
    "    if plate == \"bj\":\n",
    "        return \"category_ndbg_bj\"      # 北交所\n",
    "    return \"category_ndbg_szsh\"        # 深沪主板大类\n",
    "\n",
    "# —— 调用接口 ——\n",
    "def get_report(page_num: int, date_range: str, column: str, plate: str) -> requests.Response:\n",
    "    url = \"http://www.cninfo.com.cn/new/hisAnnouncement/query\"\n",
    "    payload = {\n",
    "        \"pageNum\":   page_num,\n",
    "        \"pageSize\":  30,\n",
    "        \"column\":    column,\n",
    "        \"tabName\":   \"fulltext\",\n",
    "        \"category\":  category_for_plate(plate),\n",
    "        \"plate\":     plate,\n",
    "        \"searchkey\": \"\",\n",
    "        \"secid\":     \"\",\n",
    "        \"trade\":     \"\",\n",
    "        \"seDate\":    date_range,\n",
    "        \"sortName\":  \"code\",\n",
    "        \"sortType\":  \"asc\",\n",
    "        \"isHLtitle\": \"false\",\n",
    "    }\n",
    "    headers = {\n",
    "        \"Accept\":           \"*/*\",\n",
    "        \"Accept-Language\":  \"zh-CN,zh;q=0.9\",\n",
    "        \"Content-Type\":     \"application/x-www-form-urlencoded; charset=UTF-8\",\n",
    "        \"Origin\":           \"http://www.cninfo.com.cn\",\n",
    "        \"Referer\":          \"http://www.cninfo.com.cn/new/commonUrl/pageOfSearch?url=disclosure/list/search\",\n",
    "        \"User-Agent\":       \"Mozilla/5.0\",\n",
    "        \"X-Requested-With\": \"XMLHttpRequest\",\n",
    "    }\n",
    "    return requests.post(url, data=payload, headers=headers, timeout=15)\n",
    "\n",
    "# —— 分段抓取（先粗过滤再汇总） ——\n",
    "def download_reports_for_segments(segments: List[str], column: str, plate: str) -> List[Dict]:\n",
    "    all_ann: List[Dict] = []\n",
    "    seen = set()  # 去重：用 (secCode, adjunctUrl)\n",
    "    for date_range in segments:\n",
    "        try:\n",
    "            total = get_report(1, date_range, column, plate).json().get(\"totalpages\", 0)\n",
    "        except Exception:\n",
    "            continue\n",
    "        if total <= 0:\n",
    "            continue\n",
    "\n",
    "        page = 1\n",
    "        while page <= total:\n",
    "            for _ in range(3):  # 重试三次\n",
    "                try:\n",
    "                    resp = get_report(page, date_range, column, plate)\n",
    "                    resp.raise_for_status()\n",
    "                    anns = resp.json().get(\"announcements\", [])\n",
    "                    # 当场做一次标题粗过滤 + 去重\n",
    "                    for x in anns:\n",
    "                        title = x.get(\"announcementTitle\", \"\")\n",
    "                        if not is_valid_cn_annual_2024(title):\n",
    "                            continue\n",
    "                        key = (str(x.get(\"secCode\", \"\")), str(x.get(\"adjunctUrl\", \"\")))\n",
    "                        if key in seen:\n",
    "                            continue\n",
    "                        seen.add(key)\n",
    "                        all_ann.append(x)\n",
    "                    break\n",
    "                except Exception:\n",
    "                    time.sleep(1.5)\n",
    "            page += 1\n",
    "    return all_ann\n",
    "\n",
    "# —— 最新版本优先（更正/修订/更新 > 时间更近） ——\n",
    "REV_KWS = [\"更正\", \"修订\", \"更新\"]\n",
    "def ann_weight(it: Dict) -> Tuple[int, int]:\n",
    "    title = norm(it.get(\"announcementTitle\", \"\"))\n",
    "    w1 = 10 if any(k in title for k in REV_KWS) else 0\n",
    "    try:\n",
    "        ts = int(it.get(\"announcementTime\", 0))\n",
    "    except Exception:\n",
    "        ts = 0\n",
    "    return (w1, ts)\n",
    "\n",
    "def filter_latest_versions(anns: List[Dict]) -> List[Dict]:\n",
    "    latest: Dict[Tuple[str, str], Dict] = {}\n",
    "    for it in anns:\n",
    "        sec = str(it.get(\"secCode\", \"\"))\n",
    "        yr  = extract_year(it.get(\"announcementTitle\", \"\"))\n",
    "        if not sec or yr != str(YEAR):\n",
    "            continue\n",
    "        key = (sec, yr)\n",
    "        if key not in latest or ann_weight(it) > ann_weight(latest[key]):\n",
    "            latest[key] = it\n",
    "    return list(latest.values())\n",
    "\n",
    "# —— 统一抓取入口（两段时间，提速） ——\n",
    "def collect_all_announcements(year: int) -> List[Dict]:\n",
    "    ny = year + 1\n",
    "    segments = [\n",
    "        f\"{ny}-01-01~{ny}-04-30\",  # 主体披露期\n",
    "        f\"{ny}-05-01~{ny}-12-31\",  # 补报/延期\n",
    "    ]\n",
    "    raw: List[Dict] = []\n",
    "    for col in MARKETS:\n",
    "        for pl in PLATES:\n",
    "            raw.extend(download_reports_for_segments(segments, col, pl))\n",
    "    return filter_latest_versions(raw)\n",
    "\n",
    "# —— 写 Excel —— \n",
    "def write_selected_excel(anns: List[Dict], year: int) -> None:\n",
    "    df_map = pd.read_excel(mapping_file, dtype=str).fillna(\"\")\n",
    "    df_map[\"sec_no_suf\"] = df_map[\"正股代码\"].str.split(\".\").str[0]\n",
    "\n",
    "    ann_dict = {\n",
    "        (str(it.get(\"secCode\", \"\")), extract_year(it.get(\"announcementTitle\", \"\"))): it\n",
    "        for it in anns\n",
    "    }\n",
    "\n",
    "    wb = openpyxl.Workbook()\n",
    "    ws = wb.active\n",
    "    ws.title = f\"{year}年报\"\n",
    "    ws.append([\"可转债代码\",\"可转债名称\",\"公司代码\",\"公司简称\",\"标题\",\"年份\",\"年报链接\"])\n",
    "\n",
    "    for _, row in df_map.iterrows():\n",
    "        bond_code = row.get(\"代码\", \"\")\n",
    "        bond_name = row.get(\"名称\", \"\")\n",
    "        sec       = row.get(\"sec_no_suf\", \"\")\n",
    "        comp_name = row.get(\"正股名称\", \"\")\n",
    "\n",
    "        it = ann_dict.get((sec, str(year)))\n",
    "        if it:\n",
    "            raw_title = re.sub(r\"<.*?>\", \"\", it.get(\"announcementTitle\",\"\")).replace(\"：\",\"\")\n",
    "            title = f\"《{raw_title}》\"\n",
    "            url   = f\"http://static.cninfo.com.cn/{it.get('adjunctUrl','')}\"\n",
    "            yr    = str(year)\n",
    "        else:\n",
    "            title = url = yr = \"\"\n",
    "\n",
    "        ws.append([bond_code, bond_name, sec, comp_name, title, yr, url])\n",
    "\n",
    "    dst = os.path.join(output_dir, f\"年报链接_{year}_选取公司{GZH}.xlsx\")\n",
    "    wb.save(dst)\n",
    "    print(f\"✅ 已输出：{dst}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    all_ann = collect_all_announcements(YEAR)\n",
    "    write_selected_excel(all_ann, YEAR)\n",
    "    print(f\"---- {YEAR} 年下载完成 ----\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
