{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sam/Library/Python/3.9/lib/python/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 正股映射已完成，结果保存在： /Users/sam/Desktop/正股映射结果.xlsx\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import efinance as ef       # pip install efinance\n",
    "\n",
    "def main():\n",
    "    # 1. 定位文件\n",
    "    in_file  = os.path.expanduser(\"~/Desktop/行情与分析20250605.xlsx\")\n",
    "    out_file = os.path.expanduser(\"~/Desktop/正股映射结果.xlsx\")\n",
    "\n",
    "    # 2. 读取原始 Excel\n",
    "    df_raw = pd.read_excel(in_file, dtype=str)  # 支持 .xlsx/.xls 等格式 :contentReference[oaicite:8]{index=8}\n",
    "\n",
    "    # 3. 拉取全市场可转债基础信息\n",
    "    #    包含字段：债券代码、债券名称、正股代码、正股名称、...... :contentReference[oaicite:9]{index=9}\n",
    "    df_all = ef.bond.get_all_base_info()\n",
    "\n",
    "    # 4. 清洗字段：提取无后缀的可转债 code 和纯数字正股 code/name\n",
    "    df_all[\"bond_code\"]  = df_all[\"债券代码\"].astype(str).str.strip()       # e.g. '110059' :contentReference[oaicite:10]{index=10}\n",
    "    df_all[\"stock_code\"] = df_all[\"正股代码\"].astype(str).str.strip()       # e.g. '600000' :contentReference[oaicite:11]{index=11}\n",
    "    df_all[\"stock_name\"] = df_all[\"正股名称\"].astype(str).str.strip()       # e.g. '浦发银行' :contentReference[oaicite:12]{index=12}\n",
    "\n",
    "    # 5. 原表中提取 bond_code（去掉 '.SH'/'.SZ' 后缀）\n",
    "    df_raw[\"bond_code\"] = df_raw[\"代码\"].str.split(\".\").str[0]\n",
    "\n",
    "    # 6. 左合并：把正股信息映射到原表\n",
    "    df_merged = df_raw.merge(\n",
    "        df_all[[\"bond_code\", \"stock_code\", \"stock_name\"]],\n",
    "        on=\"bond_code\", how=\"left\"\n",
    "    )\n",
    "\n",
    "    # 7. 构造最终列：带后缀的正股代码 + 正股名称\n",
    "    def add_suffix(code: str) -> str:\n",
    "        if not isinstance(code, str) or not code.isdigit():\n",
    "            return \"\"\n",
    "        return code + (\".SH\" if code.startswith((\"60\",\"68\")) else \".SZ\")\n",
    "\n",
    "    df_merged[\"正股代码\"] = df_merged[\"stock_code\"].apply(add_suffix)\n",
    "    df_merged[\"正股名称\"] = df_merged[\"stock_name\"].fillna(\"\")\n",
    "\n",
    "    # 8. 删除中间列并保存到 Excel\n",
    "    df_final = df_merged.drop(columns=[\"bond_code\", \"stock_code\", \"stock_name\"])\n",
    "    df_final.to_excel(out_file, index=False, engine=\"openpyxl\")  # 支持写入 .xlsx :contentReference[oaicite:13]{index=13}\n",
    "\n",
    "    print(\"✅ 正股映射已完成，结果保存在：\", out_file)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "import openpyxl\n",
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# 放到桌面上的 cninfo_output 文件夹\n",
    "output_dir = os.path.expanduser(\"~/Desktop/cninfo_output\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "GZH = \"【年报】\"\n",
    "\n",
    "def get_report(page_num, date):\n",
    "    url = \"http://www.cninfo.com.cn/new/hisAnnouncement/query\"\n",
    "    headers = {\n",
    "        \"Accept\": \"*/*\",\n",
    "        \"Accept-Encoding\": \"gzip, deflate\",\n",
    "        \"Accept-Language\": \"zh-CN,zh;q=0.9,en;q=0.8,en-GB;q=0.7,en-US;q=0.6\",\n",
    "        \"Content-Length\": \"195\",\n",
    "        \"Content-Type\": \"application/x-www-form-urlencoded; charset=UTF-8\",\n",
    "        \"Host\": \"www.cninfo.com.cn\",\n",
    "        \"Origin\": \"http://www.cninfo.com.cn\",\n",
    "        \"Proxy-Connection\": \"keep-alive\",\n",
    "        \"Referer\": \"http://www.cninfo.com.cn/new/commonUrl/pageOfSearch?url=disclosure/list/search&checkedCategory=category_ndbg_szsh\",\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/113.0.0.0 Safari/537.36 Edg/113.0.1774.42\",\n",
    "        \"X-Requested-With\": \"XMLHttpRequest\"\n",
    "    }\n",
    "    data = {\n",
    "        \"pageNum\": page_num,\n",
    "        \"pageSize\": 30,\n",
    "        \"column\": column,\n",
    "        \"tabName\": \"fulltext\",\n",
    "        \"plate\": plate,\n",
    "        \"searchkey\": \"\",\n",
    "        \"secid\": \"\",\n",
    "        \"category\": \"category_ndbg_szsh\",\n",
    "        \"trade\": trade,\n",
    "        \"seDate\": date,\n",
    "        \"sortName\": \"code\",\n",
    "        \"sortType\": \"asc\",\n",
    "        \"isHLtitle\": \"false\"\n",
    "    }\n",
    "    return requests.post(url, data=data, headers=headers)\n",
    "\n",
    "\n",
    "def download_report(date):\n",
    "    global counter\n",
    "    all_results = []\n",
    "    page_num = 1\n",
    "    resp = get_report(page_num, date)\n",
    "    try:\n",
    "        total_pages = resp.json().get(\"totalpages\", 0)\n",
    "        if total_pages == 0:\n",
    "            return all_results\n",
    "    except:\n",
    "        return all_results\n",
    "\n",
    "    max_retries = 3\n",
    "    while page_num <= total_pages:\n",
    "        retry = 0\n",
    "        while retry < max_retries:\n",
    "            try:\n",
    "                resp = get_report(page_num, date)\n",
    "                resp.raise_for_status()\n",
    "                data = resp.json()\n",
    "                if not data.get(\"announcements\"):\n",
    "                    break\n",
    "                all_results.extend(data[\"announcements\"])\n",
    "                break\n",
    "            except Exception:\n",
    "                time.sleep(5)\n",
    "                retry += 1\n",
    "        page_num += 1\n",
    "        counter += 1\n",
    "    return all_results\n",
    "\n",
    "\n",
    "# ----- 全局去重函数 -----\n",
    "def filter_latest_versions(ans):\n",
    "    keywords = ['更正','更正后','更正版','修订后','修订版','更新后','更新版']\n",
    "    latest = {}\n",
    "    for item in ans:\n",
    "        code = item['secCode']\n",
    "        m = re.search(r\"(\\d{4})年\", item['announcementTitle'])\n",
    "        yr = m.group(1) if m else ''\n",
    "        key = (code, yr)\n",
    "        title = item['announcementTitle']\n",
    "        if key not in latest or (\n",
    "            any(kw in title for kw in keywords)\n",
    "            and not any(kw in latest[key]['announcementTitle'] for kw in keywords)\n",
    "        ):\n",
    "            latest[key] = item\n",
    "    return list(latest.values())\n",
    "\n",
    "\n",
    "# ----- 只抓数据，返回所有公告列表 -----\n",
    "def download_reports_for_year(year):\n",
    "    # 1) 按时间段抓取\n",
    "    date_count = f\"{year}-01-01~{year}-12-31\"\n",
    "    _ = get_report(1, date_count).json().get(\"totalpages\", 0)\n",
    "    year += 1\n",
    "    all_results = []\n",
    "    time_segments = [\n",
    "        f\"{year}-01-01~{year}-04-01\",\n",
    "        f\"{year}-04-02~{year}-04-15\",\n",
    "        f\"{year}-04-16~{year}-04-22\",\n",
    "        f\"{year}-04-23~{year}-04-26\",\n",
    "        f\"{year}-04-27~{year}-04-28\",\n",
    "        f\"{year}-04-29~{year}-04-30\",\n",
    "        f\"{year}-05-01~{year}-07-31\",\n",
    "        f\"{year}-08-01~{year}-10-31\",\n",
    "        f\"{year}-11-01~{year}-11-30\",\n",
    "        f\"{year}-12-01~{year}-12-31\"\n",
    "    ]\n",
    "    for segment in time_segments:\n",
    "        all_results.extend(download_report(segment))\n",
    "\n",
    "    # 2) 排除“摘要”，再版本去重\n",
    "    results = [item for item in all_results if \"摘要\" not in item[\"announcementTitle\"]]\n",
    "    results = filter_latest_versions(results)\n",
    "    return results\n",
    "\n",
    "\n",
    "# ----- 把公告列表写到 Excel -----\n",
    "def write_to_excel(results, filepath):\n",
    "    wb = openpyxl.Workbook()\n",
    "    ws = wb.active\n",
    "    ws.title = \"年报\"\n",
    "    ws.append([\"公司代码\", \"公司简称\", \"标题\", \"年份\", \"年报链接\"])\n",
    "    for item in results:\n",
    "        code = item[\"secCode\"]\n",
    "        name = item[\"secName\"]\n",
    "        title = re.sub(r\"<.*?>\", \"\", item[\"announcementTitle\"]).replace(\"：\", \"\")\n",
    "        title = f\"《{title}》\"\n",
    "        m = re.search(r\"(\\d{4})年\", title)\n",
    "        year_str = m.group(1) if m else \"\"\n",
    "        url = f\"http://static.cninfo.com.cn/{item['adjunctUrl']}\"\n",
    "        if not any(kw in title for kw in exclude_keywords):\n",
    "            ws.append([code, name, title, year_str, url])\n",
    "    wb.save(filepath)\n",
    "    print(f\"已保存：{filepath}\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    exclude_keywords = ['英文','已取消','摘要']\n",
    "    trade = \"\"\n",
    "    # 循环抓取：深市 + 沪市\n",
    "    mapping_file = os.path.expanduser(\"~/Desktop/正股映射结果.xlsx\")\n",
    "    df_map = pd.read_excel(mapping_file, dtype=str)\n",
    "    secCode = df_map[\"正股代码\"].str.split(\".\").str[0].tolist()\n",
    "    secName = df_map[\"正股名称\"].tolist()\n",
    "\n",
    "    global counter\n",
    "    counter = 1\n",
    "    setYear = 2024\n",
    "\n",
    "    def filter_excel(year):\n",
    "        src = os.path.join(output_dir, f\"年报链接_{year}{GZH}.xlsx\")\n",
    "        wb = openpyxl.load_workbook(src)\n",
    "        ws = wb.active\n",
    "        rows = list(ws.iter_rows(values_only=True))\n",
    "        header = rows[0]\n",
    "        filtered = [header] + [\n",
    "            r for r in rows[1:]\n",
    "            if str(r[0]) in secCode or str(r[1]) in secName\n",
    "        ]\n",
    "        wb_new = openpyxl.Workbook()\n",
    "        ws_new = wb_new.active\n",
    "        for r in filtered:\n",
    "            ws_new.append(r)\n",
    "        dst = os.path.join(output_dir, f\"年报链接_{year}_选取公司.xlsx\")\n",
    "        wb_new.save(dst)\n",
    "        print(f\"过滤完成: {dst}\")\n",
    "\n",
    "    # 先拉深市+沪市公告，合并后写成一份完整链接表\n",
    "    combined = []\n",
    "    for column in (\"szse\", \"shse\"):\n",
    "        plate = \"\"  # 不限制板块\n",
    "        batch = download_reports_for_year(setYear)\n",
    "        combined.extend(batch)\n",
    "\n",
    "    full_path = os.path.join(output_dir, f\"年报链接_{setYear}{GZH}.xlsx\")\n",
    "    write_to_excel(combined, full_path)\n",
    "\n",
    "    # 再过滤出映射表中的公司\n",
    "    filter_excel(setYear)\n",
    "    print(f\"----{setYear}年下载完成，完整链接保存在 {full_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已保存：/Users/sam/Desktop/cninfo_output/年报链接_2024【年报】.xlsx\n",
      "过滤完成: /Users/sam/Desktop/cninfo_output/年报链接_2024_选取公司.xlsx\n",
      "----2024年下载完成，完整链接保存在 /Users/sam/Desktop/cninfo_output/年报链接_2024【年报】.xlsx\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import re\n",
    "import openpyxl\n",
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# 放到桌面上的 cninfo_output 文件夹\n",
    "output_dir = os.path.expanduser(\"~/Desktop/cninfo_output\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "GZH = \"【年报】\"\n",
    "\n",
    "def get_report(page_num, date):\n",
    "    url = \"http://www.cninfo.com.cn/new/hisAnnouncement/query\"\n",
    "    headers = {\n",
    "        \"Accept\": \"*/*\",\n",
    "        \"Accept-Encoding\": \"gzip, deflate\",\n",
    "        \"Accept-Language\": \"zh-CN,zh;q=0.9,en;q=0.8,en-GB;q=0.7,en-US;q=0.6\",\n",
    "        \"Content-Length\": \"195\",\n",
    "        \"Content-Type\": \"application/x-www-form-urlencoded; charset=UTF-8\",\n",
    "        \"Host\": \"www.cninfo.com.cn\",\n",
    "        \"Origin\": \"http://www.cninfo.com.cn\",\n",
    "        \"Proxy-Connection\": \"keep-alive\",\n",
    "        \"Referer\": \"http://www.cninfo.com.cn/new/commonUrl/pageOfSearch?url=disclosure/list/search&checkedCategory=category_ndbg_szsh\",\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/113.0.0.0 Safari/537.36 Edg/113.0.1774.42\",\n",
    "        \"X-Requested-With\": \"XMLHttpRequest\"\n",
    "    }\n",
    "    data = {\n",
    "        \"pageNum\": page_num,\n",
    "        \"pageSize\": 30,\n",
    "        \"column\": column,\n",
    "        \"tabName\": \"fulltext\",\n",
    "        \"plate\": plate,\n",
    "        \"searchkey\": \"\",\n",
    "        \"secid\": \"\",\n",
    "        \"category\": \"category_ndbg_szsh\",\n",
    "        \"trade\": trade,\n",
    "        \"seDate\": date,\n",
    "        \"sortName\": \"code\",\n",
    "        \"sortType\": \"asc\",\n",
    "        \"isHLtitle\": \"false\"\n",
    "    }\n",
    "    return requests.post(url, data=data, headers=headers)\n",
    "\n",
    "\n",
    "def download_report(date):\n",
    "    global counter\n",
    "    all_results = []\n",
    "    page_num = 1\n",
    "    resp = get_report(page_num, date)\n",
    "    try:\n",
    "        total_pages = resp.json().get(\"totalpages\", 0)\n",
    "        if total_pages == 0:\n",
    "            return all_results\n",
    "    except:\n",
    "        return all_results\n",
    "\n",
    "    max_retries = 3\n",
    "    while page_num <= total_pages:\n",
    "        retry = 0\n",
    "        while retry < max_retries:\n",
    "            try:\n",
    "                resp = get_report(page_num, date)\n",
    "                resp.raise_for_status()\n",
    "                data = resp.json()\n",
    "                if not data.get(\"announcements\"):\n",
    "                    break\n",
    "                all_results.extend(data[\"announcements\"])\n",
    "                break\n",
    "            except Exception:\n",
    "                time.sleep(5)\n",
    "                retry += 1\n",
    "        page_num += 1\n",
    "        counter += 1\n",
    "    return all_results\n",
    "\n",
    "\n",
    "# ----- 全局去重函数 -----\n",
    "def filter_latest_versions(ans):\n",
    "    keywords = ['更正','更正后','更正版','修订后','修订版','更新后','更新版']\n",
    "    latest = {}\n",
    "    for item in ans:\n",
    "        code = item['secCode']\n",
    "        m = re.search(r\"(\\d{4})年\", item['announcementTitle'])\n",
    "        yr = m.group(1) if m else ''\n",
    "        key = (code, yr)\n",
    "        title = item['announcementTitle']\n",
    "        if key not in latest or (\n",
    "            any(kw in title for kw in keywords)\n",
    "            and not any(kw in latest[key]['announcementTitle'] for kw in keywords)\n",
    "        ):\n",
    "            latest[key] = item\n",
    "    return list(latest.values())\n",
    "\n",
    "\n",
    "# ----- 只抓数据，返回所有公告列表 -----\n",
    "def download_reports_for_year(year):\n",
    "    # 1) 按时间段抓取\n",
    "    date_count = f\"{year}-01-01~{year}-12-31\"\n",
    "    _ = get_report(1, date_count).json().get(\"totalpages\", 0)\n",
    "    year += 1\n",
    "    all_results = []\n",
    "    time_segments = [\n",
    "        f\"{year}-01-01~{year}-04-01\",\n",
    "        f\"{year}-04-02~{year}-04-15\",\n",
    "        f\"{year}-04-16~{year}-04-22\",\n",
    "        f\"{year}-04-23~{year}-04-26\",\n",
    "        f\"{year}-04-27~{year}-04-28\",\n",
    "        f\"{year}-04-29~{year}-04-30\",\n",
    "        f\"{year}-05-01~{year}-07-31\",\n",
    "        f\"{year}-08-01~{year}-10-31\",\n",
    "        f\"{year}-11-01~{year}-11-30\",\n",
    "        f\"{year}-12-01~{year}-12-31\"\n",
    "    ]\n",
    "    for segment in time_segments:\n",
    "        all_results.extend(download_report(segment))\n",
    "\n",
    "    # 2) 排除“摘要”，再版本去重\n",
    "    results = [item for item in all_results if \"摘要\" not in item[\"announcementTitle\"]]\n",
    "    results = filter_latest_versions(results)\n",
    "    return results\n",
    "\n",
    "\n",
    "# ----- 把公告列表写到 Excel -----\n",
    "def write_to_excel(results, filepath):\n",
    "    wb = openpyxl.Workbook()\n",
    "    ws = wb.active\n",
    "    ws.title = \"年报\"\n",
    "    ws.append([\"公司代码\", \"公司简称\", \"标题\", \"年份\", \"年报链接\"])\n",
    "    for item in results:\n",
    "        code = item[\"secCode\"]\n",
    "        name = item[\"secName\"]\n",
    "        title = re.sub(r\"<.*?>\", \"\", item[\"announcementTitle\"]).replace(\"：\", \"\")\n",
    "        title = f\"《{title}》\"\n",
    "        m = re.search(r\"(\\d{4})年\", title)\n",
    "        year_str = m.group(1) if m else \"\"\n",
    "        url = f\"http://static.cninfo.com.cn/{item['adjunctUrl']}\"\n",
    "        if not any(kw in title for kw in exclude_keywords):\n",
    "            ws.append([code, name, title, year_str, url])\n",
    "    wb.save(filepath)\n",
    "    print(f\"已保存：{filepath}\")\n",
    "\n",
    "\n",
    "def filter_excel(year):\n",
    "    # 导入 pandas\n",
    "    import pandas as pd\n",
    "\n",
    "    # 读取完整链接表\n",
    "    src = os.path.join(output_dir, f\"年报链接_{year}{GZH}.xlsx\")\n",
    "    df_ann = pd.read_excel(src, dtype=str)\n",
    "\n",
    "    # 读取正股映射结果\n",
    "    df_map = pd.read_excel(mapping_file, dtype=str)\n",
    "    # 提取无后缀的正股代码\n",
    "    df_map['stock_code_no_suffix'] = df_map['正股代码'].str.split('.').str[0]\n",
    "\n",
    "    records = []\n",
    "    for _, row in df_map.iterrows():\n",
    "        bond_code = row['代码']        # 可转债代码\n",
    "        bond_name = row['名称']        # 可转债名称\n",
    "        stock_code = row['stock_code_no_suffix']\n",
    "\n",
    "        # 匹配该正股代码的所有年报链接\n",
    "        df_matched = df_ann[df_ann['公司代码'] == stock_code]\n",
    "        for _, ann in df_matched.iterrows():\n",
    "            records.append({\n",
    "                '可转债代码': bond_code,\n",
    "                '可转债名称': bond_name,\n",
    "                '公司代码':   ann['公司代码'],\n",
    "                '公司简称':   ann['公司简称'],\n",
    "                '标题':      ann['标题'],\n",
    "                '年份':      ann['年份'],\n",
    "                '年报链接':   ann['年报链接'],\n",
    "            })\n",
    "\n",
    "    # 按映射顺序输出\n",
    "    df_out = pd.DataFrame(records, columns=[\n",
    "        '可转债代码', '可转债名称',\n",
    "        '公司代码', '公司简称', '标题', '年份', '年报链接'\n",
    "    ])\n",
    "    dst = os.path.join(output_dir, f\"年报链接_{year}_选取公司.xlsx\")\n",
    "    df_out.to_excel(dst, index=False, engine=\"openpyxl\")\n",
    "    print(f\"过滤完成: {dst}\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    exclude_keywords = ['英文', '已取消', '摘要']\n",
    "    trade = \"\"\n",
    "    # 映射表路径\n",
    "    mapping_file = os.path.expanduser(\"~/Desktop/正股映射结果.xlsx\")\n",
    "    df_map = pd.read_excel(mapping_file, dtype=str)\n",
    "    secCode = df_map[\"正股代码\"].str.split(\".\").str[0].tolist()\n",
    "    secName = df_map[\"正股名称\"].tolist()\n",
    "\n",
    "    global counter\n",
    "    counter = 1\n",
    "    setYear = 2024\n",
    "\n",
    "    # 第一步：深市 + 沪市公告抓取\n",
    "    combined = []\n",
    "    for column in (\"szse\", \"shse\"):\n",
    "        plate = \"\"  # 不限制板块\n",
    "        batch = download_reports_for_year(setYear)\n",
    "        combined.extend(batch)\n",
    "\n",
    "    # 写出完整链接表\n",
    "    full_path = os.path.join(output_dir, f\"年报链接_{setYear}{GZH}.xlsx\")\n",
    "    write_to_excel(combined, full_path)\n",
    "\n",
    "    # 第二步：过滤并按映射顺序导出\n",
    "    filter_excel(setYear)\n",
    "    print(f\"----{setYear}年下载完成，完整链接保存在 {full_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 全量链接已保存：/Users/sam/Desktop/cninfo_output/年报链接_2024【年报2024】.xlsx\n",
      "✅ 过滤后链接已保存：/Users/sam/Desktop/cninfo_output/年报链接_2024_选取公司.xlsx\n",
      "---- 2024 年下载完成：全量链接=5343 条 ----\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import re\n",
    "import openpyxl\n",
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# —— 配置年度，只需修改这里即可 —— \n",
    "YEAR = 2024\n",
    "\n",
    "# 放到桌面上的 cninfo_output 文件夹\n",
    "output_dir = os.path.expanduser(\"~/Desktop/cninfo_output\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "GZH = f\"【年报{YEAR}】\"\n",
    "exclude_keywords = ['英文', '已取消', '摘要']\n",
    "trade = \"\"\n",
    "\n",
    "def get_report(page_num, date):\n",
    "    url = \"http://www.cninfo.com.cn/new/hisAnnouncement/query\"\n",
    "    headers = {\n",
    "        \"Accept\": \"*/*\",\n",
    "        \"Accept-Encoding\": \"gzip, deflate\",\n",
    "        \"Accept-Language\": \"zh-CN,zh;q=0.9,en;q=0.8\",\n",
    "        \"Content-Type\": \"application/x-www-form-urlencoded; charset=UTF-8\",\n",
    "        \"Origin\": \"http://www.cninfo.com.cn\",\n",
    "        \"Referer\": \"http://www.cninfo.com.cn/new/commonUrl/pageOfSearch\"\n",
    "                   \"?url=disclosure/list/search&checkedCategory=category_ndbg_szsh\",\n",
    "        \"User-Agent\": \"Mozilla/5.0\",\n",
    "        \"X-Requested-With\": \"XMLHttpRequest\"\n",
    "    }\n",
    "    data = {\n",
    "        \"pageNum\":      page_num,\n",
    "        \"pageSize\":     30,\n",
    "        \"column\":       column,\n",
    "        \"tabName\":      \"fulltext\",\n",
    "        \"plate\":        plate,\n",
    "        \"searchkey\":    \"\",\n",
    "        \"secid\":        \"\",\n",
    "        \"category\":     \"category_ndbg_szsh\",\n",
    "        \"trade\":        trade,\n",
    "        \"seDate\":       date,\n",
    "        \"sortName\":     \"code\",\n",
    "        \"sortType\":     \"asc\",\n",
    "        \"isHLtitle\":    \"false\"\n",
    "    }\n",
    "    return requests.post(url, data=data, headers=headers)\n",
    "\n",
    "\n",
    "def download_report(date):\n",
    "    global counter\n",
    "    all_results = []\n",
    "    page_num = 1\n",
    "    resp = get_report(page_num, date)\n",
    "    try:\n",
    "        total_pages = resp.json().get(\"totalpages\", 0)\n",
    "        if total_pages == 0:\n",
    "            return all_results\n",
    "    except:\n",
    "        return all_results\n",
    "\n",
    "    max_retries = 3\n",
    "    while page_num <= total_pages:\n",
    "        retry = 0\n",
    "        while retry < max_retries:\n",
    "            try:\n",
    "                resp = get_report(page_num, date)\n",
    "                resp.raise_for_status()\n",
    "                data = resp.json()\n",
    "                if not data.get(\"announcements\"):\n",
    "                    break\n",
    "                all_results.extend(data[\"announcements\"])\n",
    "                break\n",
    "            except Exception:\n",
    "                time.sleep(5)\n",
    "                retry += 1\n",
    "        page_num += 1\n",
    "        counter += 1\n",
    "    return all_results\n",
    "\n",
    "\n",
    "# ----- 全局去重函数 -----\n",
    "def filter_latest_versions(ans):\n",
    "    keywords = ['更正','更正后','更正版','修订后','修订版','更新后','更新版']\n",
    "    latest = {}\n",
    "    for item in ans:\n",
    "        code = item['secCode']\n",
    "        m = re.search(r\"(\\d{4})年\", item['announcementTitle'])\n",
    "        yr = m.group(1) if m else ''\n",
    "        key = (code, yr)\n",
    "        title = item['announcementTitle']\n",
    "        if key not in latest or (\n",
    "            any(kw in title for kw in keywords)\n",
    "            and not any(kw in latest[key]['announcementTitle'] for kw in keywords)\n",
    "        ):\n",
    "            latest[key] = item\n",
    "    return list(latest.values())\n",
    "\n",
    "\n",
    "# ----- 只抓数据，返回所有公告列表 -----\n",
    "def download_reports_for_year(year):\n",
    "    # 1) 按时间段抓取上一年全量公告\n",
    "    date_count = f\"{year}-01-01~{year}-12-31\"\n",
    "    _ = get_report(1, date_count).json().get(\"totalpages\", 0)\n",
    "\n",
    "    # 切换到下一年分段抓取，保证覆盖跨年发布的公告\n",
    "    next_year = year + 1\n",
    "    time_segments = [\n",
    "        f\"{next_year}-01-01~{next_year}-04-01\",\n",
    "        f\"{next_year}-04-02~{next_year}-04-15\",\n",
    "        f\"{next_year}-04-16~{next_year}-04-22\",\n",
    "        f\"{next_year}-04-23~{next_year}-04-26\",\n",
    "        f\"{next_year}-04-27~{next_year}-04-28\",\n",
    "        f\"{next_year}-04-29~{next_year}-04-30\",\n",
    "        f\"{next_year}-05-01~{next_year}-07-31\",\n",
    "        f\"{next_year}-08-01~{next_year}-10-31\",\n",
    "        f\"{next_year}-11-01~{next_year}-11-30\",\n",
    "        f\"{next_year}-12-01~{next_year}-12-31\"\n",
    "    ]\n",
    "\n",
    "    all_results = []\n",
    "    for segment in time_segments:\n",
    "        all_results.extend(download_report(segment))\n",
    "\n",
    "    # 2) 排除“摘要”，再版本去重\n",
    "    filtered = [item for item in all_results if \"摘要\" not in item[\"announcementTitle\"]]\n",
    "    return filter_latest_versions(filtered)\n",
    "\n",
    "\n",
    "# ----- 把公告列表写到 Excel —— 全量链接 —— \n",
    "def write_all_to_excel(results, filepath):\n",
    "    wb = openpyxl.Workbook()\n",
    "    ws = wb.active\n",
    "    ws.title = f\"{YEAR}年报\"\n",
    "    ws.append([\"公司代码\", \"公司简称\", \"标题\", \"年份\", \"年报链接\"])\n",
    "    for item in results:\n",
    "        code = item[\"secCode\"]\n",
    "        name = item[\"secName\"]\n",
    "        title = re.sub(r\"<.*?>\", \"\", item[\"announcementTitle\"]).replace(\"：\", \"\")\n",
    "        title = f\"《{title}》\"\n",
    "        m = re.search(r\"(\\d{4})年\", title)\n",
    "        year_str = m.group(1) if m else \"\"\n",
    "        url = f\"http://static.cninfo.com.cn/{item['adjunctUrl']}\"\n",
    "        if not any(kw in title for kw in exclude_keywords):\n",
    "            ws.append([code, name, title, year_str, url])\n",
    "    wb.save(filepath)\n",
    "    print(f\"✅ 全量链接已保存：{filepath}\")\n",
    "\n",
    "\n",
    "# ----- 把公告列表写到 Excel —— 按映射过滤 —— \n",
    "def filter_excel(year):\n",
    "    import pandas as pd\n",
    "    # 读取全量链接表\n",
    "    src = os.path.join(output_dir, f\"年报链接_{year}{GZH}.xlsx\")\n",
    "    df_ann = pd.read_excel(src, dtype=str)\n",
    "\n",
    "    # 读取正股映射结果\n",
    "    df_map = pd.read_excel(mapping_file, dtype=str)\n",
    "    df_map['stock_code_no_suffix'] = df_map['正股代码'].str.split('.').str[0]\n",
    "\n",
    "    records = []\n",
    "    for _, row in df_map.iterrows():\n",
    "        bond_code = row['代码']\n",
    "        bond_name = row['名称']\n",
    "        stock_code = row['stock_code_no_suffix']\n",
    "        df_matched = df_ann[df_ann['公司代码'] == stock_code]\n",
    "        for _, ann in df_matched.iterrows():\n",
    "            records.append({\n",
    "                '可转债代码': bond_code,\n",
    "                '可转债名称': bond_name,\n",
    "                '公司代码':   ann['公司代码'],\n",
    "                '公司简称':   ann['公司简称'],\n",
    "                '标题':      ann['标题'],\n",
    "                '年份':      ann['年份'],\n",
    "                '年报链接':   ann['年报链接'],\n",
    "            })\n",
    "\n",
    "    df_out = pd.DataFrame(records, columns=[\n",
    "        '可转债代码', '可转债名称',\n",
    "        '公司代码', '公司简称', '标题', '年份', '年报链接'\n",
    "    ])\n",
    "    dst = os.path.join(output_dir, f\"年报链接_{year}_选取公司.xlsx\")\n",
    "    df_out.to_excel(dst, index=False, engine=\"openpyxl\")\n",
    "    print(f\"✅ 过滤后链接已保存：{dst}\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # 读取正股映射结果\n",
    "    mapping_file = os.path.expanduser(\"~/Desktop/正股映射结果.xlsx\")\n",
    "    df_map = pd.read_excel(mapping_file, dtype=str)\n",
    "    secCode = df_map[\"正股代码\"].str.split(\".\").str[0].tolist()\n",
    "    secName = df_map[\"正股名称\"].tolist()\n",
    "\n",
    "    global counter\n",
    "    counter = 1\n",
    "\n",
    "    # 第一步：抓取全量公告链接\n",
    "    all_links = []\n",
    "    for column in (\"szse\", \"shse\"):\n",
    "        plate = \"\"\n",
    "        batch = download_reports_for_year(YEAR)\n",
    "        all_links.extend(batch)\n",
    "\n",
    "    # 写出“全量”年报链接\n",
    "    full_path = os.path.join(output_dir, f\"年报链接_{YEAR}{GZH}.xlsx\")\n",
    "    write_all_to_excel(all_links, full_path)\n",
    "\n",
    "    # 第二步：按映射结果过滤并导出\n",
    "    filter_excel(YEAR)\n",
    "\n",
    "    print(f\"---- {YEAR} 年下载完成：全量链接={len(all_links)} 条 ----\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已保存：/Users/sam/Desktop/cninfo_output/年报链接_2024【年报2024】.xlsx\n",
      "过滤完成：/Users/sam/Desktop/cninfo_output/年报链接_2024_选取公司.xlsx\n",
      "---- 2024 年下载完成，共 5343 条链接 ----\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "import requests\n",
    "import openpyxl\n",
    "import pandas as pd\n",
    "\n",
    "# —— 配置区 —— \n",
    "YEAR = 2024  # 修改此处即可调整年度\n",
    "GZH = f\"【年报{YEAR}】\"\n",
    "exclude_keywords = ['英文', '已取消', '摘要']\n",
    "trade = \"\"\n",
    "plate = \"\"\n",
    "\n",
    "# 输出目录\n",
    "output_dir = os.path.expanduser(\"~/Desktop/cninfo_output\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# 正股映射表路径（用于第二步过滤）\n",
    "mapping_file = os.path.expanduser(\"~/Desktop/正股映射结果.xlsx\")\n",
    "\n",
    "\n",
    "def get_report(page_num: int, date_range: str) -> requests.Response:\n",
    "    \"\"\"\n",
    "    调用巨潮网历史公告查询接口\n",
    "    \"\"\"\n",
    "    url = \"http://www.cninfo.com.cn/new/hisAnnouncement/query\"\n",
    "    headers = {\n",
    "        \"Accept\": \"*/*\",\n",
    "        \"Accept-Encoding\": \"gzip, deflate\",\n",
    "        \"Accept-Language\": \"zh-CN,zh;q=0.9\",\n",
    "        \"Content-Type\": \"application/x-www-form-urlencoded; charset=UTF-8\",\n",
    "        \"Origin\": \"http://www.cninfo.com.cn\",\n",
    "        \"Referer\": (\n",
    "            \"http://www.cninfo.com.cn/new/commonUrl/\"\n",
    "            \"pageOfSearch?url=disclosure/list/search\"\n",
    "            \"&checkedCategory=category_ndbg_szsh\"\n",
    "        ),\n",
    "        \"User-Agent\": \"Mozilla/5.0\",\n",
    "        \"X-Requested-With\": \"XMLHttpRequest\"\n",
    "    }\n",
    "    payload = {\n",
    "        \"pageNum\": page_num,\n",
    "        \"pageSize\": 30,\n",
    "        \"column\": column,\n",
    "        \"tabName\": \"fulltext\",\n",
    "        \"plate\": plate,\n",
    "        \"searchkey\": \"\",\n",
    "        \"secid\": \"\",\n",
    "        \"category\": \"category_ndbg_szsh\",\n",
    "        \"trade\": trade,\n",
    "        \"seDate\": date_range,\n",
    "        \"sortName\": \"code\",\n",
    "        \"sortType\": \"asc\",\n",
    "        \"isHLtitle\": \"false\"\n",
    "    }\n",
    "    return requests.post(url, data=payload, headers=headers)\n",
    "\n",
    "\n",
    "def download_report(date_range: str) -> list[dict]:\n",
    "    \"\"\"\n",
    "    分页下载单个时间段内的所有公告\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    page = 1\n",
    "    resp = get_report(page, date_range)\n",
    "    try:\n",
    "        total_pages = resp.json().get(\"totalpages\", 0)\n",
    "    except Exception:\n",
    "        return results\n",
    "    if total_pages == 0:\n",
    "        return results\n",
    "\n",
    "    while page <= total_pages:\n",
    "        for attempt in range(3):\n",
    "            resp = get_report(page, date_range)\n",
    "            try:\n",
    "                resp.raise_for_status()\n",
    "                ann = resp.json().get(\"announcements\", [])\n",
    "                if ann:\n",
    "                    results.extend(ann)\n",
    "                break\n",
    "            except Exception:\n",
    "                time.sleep(5)\n",
    "        page += 1\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def filter_latest_versions(announcements: list[dict]) -> list[dict]:\n",
    "    \"\"\"\n",
    "    同一公司同一年只保留最新“更正/修订”版本\n",
    "    \"\"\"\n",
    "    rev_kws = ['更正','更正后','更正版','修订后','修订版','更新后','更新版']\n",
    "    latest = {}\n",
    "    for item in announcements:\n",
    "        sec = item['secCode']\n",
    "        title = item['announcementTitle']\n",
    "        year_match = re.search(r\"(\\d{4})年\", title)\n",
    "        year_str = year_match.group(1) if year_match else \"\"\n",
    "        key = (sec, year_str)\n",
    "        if key not in latest:\n",
    "            latest[key] = item\n",
    "        else:\n",
    "            curr = latest[key]['announcementTitle']\n",
    "            # 如果本条是修订/更正版，而已有条目不是，则覆盖\n",
    "            if any(kw in title for kw in rev_kws) and not any(kw in curr for kw in rev_kws):\n",
    "                latest[key] = item\n",
    "    return list(latest.values())\n",
    "\n",
    "\n",
    "def download_reports_for_year(year: int) -> list[dict]:\n",
    "    \"\"\"\n",
    "    抓取上一年发布的年度报告公告：\n",
    "    1) 主时间段：year-01-01~year-12-31\n",
    "    2) 次年分段：year+1 的若干子区间\n",
    "    \"\"\"\n",
    "    # 主查询时间段\n",
    "    main_range = f\"{year}-01-01~{year}-12-31\"\n",
    "    _ = get_report(1, main_range).json().get(\"totalpages\", 0)\n",
    "\n",
    "    # 次年分段，以捕获跨年发布时间\n",
    "    ny = year + 1\n",
    "    segments = [\n",
    "        f\"{ny}-01-01~{ny}-04-01\", f\"{ny}-04-02~{ny}-04-15\",\n",
    "        f\"{ny}-04-16~{ny}-04-22\", f\"{ny}-04-23~{ny}-04-26\",\n",
    "        f\"{ny}-04-27~{ny}-04-28\", f\"{ny}-04-29~{ny}-04-30\",\n",
    "        f\"{ny}-05-01~{ny}-07-31\", f\"{ny}-08-01~{ny}-10-31\",\n",
    "        f\"{ny}-11-01~{ny}-11-30\", f\"{ny}-12-01~{ny}-12-31\"\n",
    "    ]\n",
    "\n",
    "    all_ann = []\n",
    "    for seg in segments:\n",
    "        all_ann.extend(download_report(seg))\n",
    "\n",
    "    # 排除“摘要”及其他关键词\n",
    "    filtered = [\n",
    "        x for x in all_ann\n",
    "        if \"摘要\" not in x['announcementTitle']\n",
    "    ]\n",
    "    return filter_latest_versions(filtered)\n",
    "\n",
    "\n",
    "def write_to_excel(results: list[dict], filepath: str) -> None:\n",
    "    \"\"\"\n",
    "    将公告列表写入 Excel\n",
    "    \"\"\"\n",
    "    wb = openpyxl.Workbook()\n",
    "    ws = wb.active\n",
    "    ws.title = f\"{YEAR}年报\"\n",
    "    ws.append([\"公司代码\", \"公司简称\", \"标题\", \"年份\", \"年报链接\"])\n",
    "    for it in results:\n",
    "        sec = it[\"secCode\"]\n",
    "        name = it[\"secName\"]\n",
    "        raw_title = re.sub(r\"<.*?>\", \"\", it[\"announcementTitle\"]).replace(\"：\", \"\")\n",
    "        title = f\"《{raw_title}》\"\n",
    "        ym = re.search(r\"(\\d{4})年\", raw_title)\n",
    "        yr = ym.group(1) if ym else \"\"\n",
    "        url = f\"http://static.cninfo.com.cn/{it['adjunctUrl']}\"\n",
    "        if not any(kw in raw_title for kw in exclude_keywords):\n",
    "            ws.append([sec, name, title, yr, url])\n",
    "    wb.save(filepath)\n",
    "    print(f\"已保存：{filepath}\")\n",
    "\n",
    "\n",
    "def filter_excel(year: int) -> None:\n",
    "    \"\"\"\n",
    "    读取全量链接表，并根据映射表导出“选取公司”链接\n",
    "    \"\"\"\n",
    "    full = pd.read_excel(\n",
    "        os.path.join(output_dir, f\"年报链接_{year}{GZH}.xlsx\"),\n",
    "        dtype=str\n",
    "    )\n",
    "    mapping = pd.read_excel(mapping_file, dtype=str)\n",
    "    mapping['code_no_suf'] = mapping['正股代码'].str.split('.').str[0]\n",
    "\n",
    "    records = []\n",
    "    for _, row in mapping.iterrows():\n",
    "        bond_code = row['代码']\n",
    "        bond_name = row['名称']\n",
    "        sc = row['code_no_suf']\n",
    "        matched = full[full['公司代码'] == sc]\n",
    "        for _, ann in matched.iterrows():\n",
    "            records.append({\n",
    "                '可转债代码':   bond_code,\n",
    "                '可转债名称':   bond_name,\n",
    "                '公司代码':     ann['公司代码'],\n",
    "                '公司简称':     ann['公司简称'],\n",
    "                '标题':        ann['标题'],\n",
    "                '年份':        ann['年份'],\n",
    "                '年报链接':     ann['年报链接'],\n",
    "            })\n",
    "\n",
    "    df_out = pd.DataFrame(records, columns=[\n",
    "        '可转债代码', '可转债名称',\n",
    "        '公司代码', '公司简称', '标题', '年份', '年报链接'\n",
    "    ])\n",
    "    dst = os.path.join(output_dir, f\"年报链接_{year}_选取公司.xlsx\")\n",
    "    df_out.to_excel(dst, index=False, engine=\"openpyxl\")\n",
    "    print(f\"过滤完成：{dst}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 第一步：抓取并写出“全量”年报链接\n",
    "    combined = []\n",
    "    for column in (\"szse\", \"shse\"):\n",
    "        plate = \"\"\n",
    "        batch = download_reports_for_year(YEAR)\n",
    "        combined.extend(batch)\n",
    "\n",
    "    full_path = os.path.join(output_dir, f\"年报链接_{YEAR}{GZH}.xlsx\")\n",
    "    write_to_excel(combined, full_path)\n",
    "\n",
    "    # 第二步：按映射结果过滤并导出\n",
    "    filter_excel(YEAR)\n",
    "\n",
    "    print(f\"---- {YEAR} 年下载完成，共 {len(combined)} 条链接 ----\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 全量映射链接已保存： /Users/sam/Desktop/cninfo_output/年报链接_2024【年报】.xlsx\n",
      "✅ 过滤后链接已保存： /Users/sam/Desktop/cninfo_output/年报链接_2024_选取公司.xlsx\n",
      "---- 2024年 下载完成，共抓取0条链接 ----\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import re\n",
    "import openpyxl\n",
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# —— 配置区 —— \n",
    "YEAR            = 2024        # ◀ 修改这一行即可抓取对应年度\n",
    "GZH             = \"【年报】\"\n",
    "exclude_keywords = ['英文', '摘要', 'annual report', '已取消']\n",
    "trade           = \"\"\n",
    "plate           = \"\"\n",
    "\n",
    "# 文件路径\n",
    "BASE_DIR     = os.path.expanduser(\"~/Desktop/cninfo_output\")\n",
    "MAPPING_FILE = os.path.expanduser(\"~/Desktop/正股映射结果.xlsx\")\n",
    "os.makedirs(BASE_DIR, exist_ok=True)\n",
    "\n",
    "# 全局变量，用于 get_report 中填充 secid\n",
    "column = \"\"\n",
    "secid  = \"\"\n",
    "\n",
    "# —— 单页请求 —— \n",
    "def get_report(page_num, date_range):\n",
    "    url = \"http://www.cninfo.com.cn/new/hisAnnouncement/query\"\n",
    "    headers = {\n",
    "        \"Accept\": \"*/*\",\n",
    "        \"Content-Type\": \"application/x-www-form-urlencoded; charset=UTF-8\",\n",
    "        \"User-Agent\": \"Mozilla/5.0\",\n",
    "        \"X-Requested-With\": \"XMLHttpRequest\"\n",
    "    }\n",
    "    data = {\n",
    "        \"pageNum\":   page_num,\n",
    "        \"pageSize\":  30,\n",
    "        \"column\":    column,\n",
    "        \"tabName\":   \"fulltext\",\n",
    "        \"plate\":     plate,\n",
    "        \"secid\":     secid,\n",
    "        \"category\":  \"category_ndbg_szsh\",\n",
    "        \"trade\":     trade,\n",
    "        \"searchkey\": f\"{YEAR}年年度报告\",\n",
    "        \"seDate\":    date_range,\n",
    "        \"sortName\":  \"code\",\n",
    "        \"sortType\":  \"asc\",\n",
    "        \"isHLtitle\": \"false\"\n",
    "    }\n",
    "    return requests.post(url, data=data, headers=headers)\n",
    "\n",
    "# —— 分页抓取 —— \n",
    "def download_report(date_range):\n",
    "    results = []\n",
    "    # 第一次拿总页数\n",
    "    resp0 = get_report(1, date_range)\n",
    "    try:\n",
    "        total = resp0.json().get(\"totalpages\", 0)\n",
    "    except:\n",
    "        return results\n",
    "    # 翻页\n",
    "    for pn in range(1, total + 1):\n",
    "        for _ in range(3):\n",
    "            try:\n",
    "                r = get_report(pn, date_range)\n",
    "                r.raise_for_status()\n",
    "                anns = r.json().get(\"announcements\", [])\n",
    "                break\n",
    "            except:\n",
    "                time.sleep(2)\n",
    "        else:\n",
    "            continue\n",
    "        results.extend(anns)\n",
    "    return results\n",
    "\n",
    "# —— 去重：同一公司同一年仅保留最新“修订/更正”版本 —— \n",
    "def filter_latest_versions(items):\n",
    "    rev_kws = ['更正','更正后','更正版','修订后','修订版','更新后','更新版']\n",
    "    latest = {}\n",
    "    for it in items:\n",
    "        code = it['secCode']\n",
    "        yr_m = re.search(r\"(\\d{4})年\", it['announcementTitle'])\n",
    "        yr = yr_m.group(1) if yr_m else ''\n",
    "        key = (code, yr)\n",
    "        title = it['announcementTitle']\n",
    "        if key not in latest or (\n",
    "            any(kw in title for kw in rev_kws)\n",
    "            and not any(kw in latest[key]['announcementTitle'] for kw in rev_kws)\n",
    "        ):\n",
    "            latest[key] = it\n",
    "    return list(latest.values())\n",
    "\n",
    "# —— 抓取映射表公司年报 —— \n",
    "def fetch_reports_for_mapping(sec_codes):\n",
    "    # 时间分段：当年 + 次年初\n",
    "    segments = [\n",
    "        f\"{YEAR}-01-01~{YEAR}-12-31\",\n",
    "        f\"{YEAR+1}-01-01~{YEAR+1}-04-30\",\n",
    "    ]\n",
    "    all_items = []\n",
    "    for col in (\"szse\", \"shse\"):\n",
    "        global column\n",
    "        column = col\n",
    "        for code in sec_codes:\n",
    "            global secid\n",
    "            secid = f\"{col}_{code}\"\n",
    "            raw = []\n",
    "            for seg in segments:\n",
    "                raw.extend(download_report(seg))\n",
    "            # 只留中文年度报告并排除英文/摘要等\n",
    "            filtered = [\n",
    "                it for it in raw\n",
    "                if f\"{YEAR}年年度报告\" in it[\"announcementTitle\"]\n",
    "                and not any(kw in it[\"announcementTitle\"] for kw in exclude_keywords)\n",
    "            ]\n",
    "            all_items.extend(filtered)\n",
    "    return filter_latest_versions(all_items)\n",
    "\n",
    "# —— 写全量映射链接 Excel —— \n",
    "def write_all_to_excel(items, filepath):\n",
    "    wb = openpyxl.Workbook()\n",
    "    ws = wb.active\n",
    "    ws.title = f\"{YEAR}年报\"\n",
    "    ws.append([\"公司代码\",\"公司简称\",\"标题\",\"年份\",\"年报链接\"])\n",
    "    for it in items:\n",
    "        code = it[\"secCode\"]\n",
    "        name = it[\"secName\"]\n",
    "        txt  = re.sub(r\"<.*?>\",\"\", it[\"announcementTitle\"]).replace(\"：\",\"\")\n",
    "        yr_m = re.search(r\"(\\d{4})年\", txt)\n",
    "        yr   = yr_m.group(1) if yr_m else \"\"\n",
    "        url  = f\"http://static.cninfo.com.cn/{it['adjunctUrl']}\"\n",
    "        ws.append([code, name, txt, yr, url])\n",
    "    wb.save(filepath)\n",
    "    print(\"✅ 全量映射链接已保存：\", filepath)\n",
    "\n",
    "# —— 按可转债映射过滤并导出 —— \n",
    "def filter_excel(year):\n",
    "    df_ann = pd.read_excel(\n",
    "        os.path.join(BASE_DIR, f\"年报链接_{year}{GZH}.xlsx\"),\n",
    "        dtype=str\n",
    "    )\n",
    "    df_map = pd.read_excel(MAPPING_FILE, dtype=str)\n",
    "    df_map['stock_code_no_suffix'] = df_map['正股代码'].str.split('.').str[0]\n",
    "\n",
    "    records = []\n",
    "    for _, row in df_map.iterrows():\n",
    "        bc = row['代码']\n",
    "        bn = row['名称']\n",
    "        sc = row['stock_code_no_suffix']\n",
    "        subset = df_ann[df_ann['公司代码']==sc]\n",
    "        for _, r in subset.iterrows():\n",
    "            records.append({\n",
    "                '可转债代码': bc,\n",
    "                '可转债名称': bn,\n",
    "                '公司代码':   r['公司代码'],\n",
    "                '公司简称':   r['公司简称'],\n",
    "                '标题':      r['标题'],\n",
    "                '年份':      r['年份'],\n",
    "                '年报链接':   r['年报链接'],\n",
    "            })\n",
    "\n",
    "    df_out = pd.DataFrame(records, columns=[\n",
    "        '可转债代码','可转债名称',\n",
    "        '公司代码','公司简称','标题','年份','年报链接'\n",
    "    ])\n",
    "    dst = os.path.join(BASE_DIR, f\"年报链接_{year}_选取公司.xlsx\")\n",
    "    df_out.to_excel(dst, index=False, engine=\"openpyxl\")\n",
    "    print(\"✅ 过滤后链接已保存：\", dst)\n",
    "\n",
    "# —— 主流程 —— \n",
    "if __name__ == '__main__':\n",
    "    # 1) 读取正股映射，无后缀代码列表\n",
    "    df_map   = pd.read_excel(MAPPING_FILE, dtype=str)\n",
    "    secCodes = df_map['正股代码'].str.split('.').str[0].tolist()\n",
    "\n",
    "    # 2) 抓取映射全量年报链接\n",
    "    items = fetch_reports_for_mapping(secCodes)\n",
    "    full_path = os.path.join(BASE_DIR, f\"年报链接_{YEAR}{GZH}.xlsx\")\n",
    "    write_all_to_excel(items, full_path)\n",
    "\n",
    "    # 3) 根据映射结果导出“选取公司”年报链接\n",
    "    filter_excel(YEAR)\n",
    "\n",
    "    print(f\"---- {YEAR}年 下载完成，共抓取{len(items)}条链接 ----\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import os\n",
    "import re\n",
    "import logging\n",
    "from datetime import datetime\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "# 日志配置\n",
    "logging.basicConfig(level=logging.INFO, format='[%(asctime)s] %(message)s')\n",
    "\n",
    "def log(msg):\n",
    "    print(f\"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] {msg}\")\n",
    "\n",
    "# 参数配置\n",
    "BASE_DIR    = os.path.expanduser(\"~/Desktop/cninfo_output\")\n",
    "EXCEL_FILE  = os.path.join(BASE_DIR, \"年报链接_2024_选取公司.xlsx\")\n",
    "PDF_DIR     = os.path.join(BASE_DIR, \"pdf_reports_2024\")\n",
    "MAX_WORKERS = 16  # 并发线程数，可根据网络情况调整\n",
    "\n",
    "# 确保输出目录存在\n",
    "os.makedirs(PDF_DIR, exist_ok=True)\n",
    "\n",
    "# 下载单个 PDF\n",
    "def download_pdf(record):\n",
    "    code, name, year, url = record\n",
    "    safe = re.sub(r'[\\\\/:*?\"<>|]', '', f\"{code}_{name}_{year}\")\n",
    "    path = os.path.join(PDF_DIR, f\"{safe}.pdf\")\n",
    "    if os.path.exists(path):\n",
    "        log(f\"Exists, skip: {path}\")\n",
    "        return\n",
    "    try:\n",
    "        resp = requests.get(url, timeout=15)\n",
    "        content_type = resp.headers.get(\"Content-Type\", \"\").lower()\n",
    "        if resp.status_code == 200 and \"pdf\" in content_type:\n",
    "            with open(path, 'wb') as f:\n",
    "                f.write(resp.content)\n",
    "            log(f\"Downloaded: {path}\")\n",
    "        else:\n",
    "            log(f\"Failed ({resp.status_code}) or not PDF: {url}\")\n",
    "    except Exception as e:\n",
    "        log(f\"Error downloading {url}: {e}\")\n",
    "\n",
    "# 主流程\n",
    "def main():\n",
    "    log(f\"Reading Excel: {EXCEL_FILE}\")\n",
    "    if not os.path.exists(EXCEL_FILE):\n",
    "        log(\"Excel file not found. 请检查路径。\")\n",
    "        return\n",
    "    df = pd.read_excel(EXCEL_FILE)\n",
    "    records = [\n",
    "        (r['公司代码'], r['公司简称'], r['年份'], r['年报链接'])\n",
    "        for _, r in df.iterrows()\n",
    "        if str(r.get('年份')) == '2024'\n",
    "    ]\n",
    "    log(f\"Found {len(records)} records for 2024.\")\n",
    "\n",
    "    start = datetime.now()\n",
    "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
    "        futures = [executor.submit(download_pdf, rec) for rec in records]\n",
    "        for future in as_completed(futures):\n",
    "            pass\n",
    "    elapsed = (datetime.now() - start).total_seconds()\n",
    "    log(f\"All downloads completed in {elapsed:.2f}s. PDFs saved to: {PDF_DIR}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
